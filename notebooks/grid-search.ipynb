{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold \n",
    "from sklearn.preprocessing import binarize\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import classification_report, f1_score, balanced_accuracy_score\n",
    "import instructions\n",
    "import handling_outliers as ho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.split(os.getcwd())\n",
    "data_directory = os.path.join(path[0], 'data\\\\raw')\n",
    "#data_directory = os.path.join(os.getcwd(), 'data\\\\raw')\n",
    "\n",
    "\n",
    "X = instructions.load_csv(data_directory, 'train_data')\n",
    "y = instructions.load_csv(data_directory, 'train_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3750, 2)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kpca = KernelPCA(n_components=2, kernel=\"rbf\")\n",
    "\n",
    "X_kpca = kpca.fit_transform(X)\n",
    "\n",
    "X_kpca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'color' kwarg must be a color or sequence of color specs.  For a sequence of values to be color-mapped, use the 'c' argument instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\matplotlib\\axes\\_axes.py:4160\u001b[0m, in \u001b[0;36mAxes._parse_scatter_color_args\u001b[1;34m(c, edgecolors, kwargs, xsize, get_next_color_func)\u001b[0m\n\u001b[0;32m   4159\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 4160\u001b[0m     mcolors\u001b[39m.\u001b[39;49mto_rgba_array(kwcolor)\n\u001b[0;32m   4161\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\matplotlib\\colors.py:377\u001b[0m, in \u001b[0;36mto_rgba_array\u001b[1;34m(c, alpha)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 377\u001b[0m     rgba \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([to_rgba(cc) \u001b[39mfor\u001b[39;00m cc \u001b[39min\u001b[39;00m c])\n\u001b[0;32m    379\u001b[0m \u001b[39mif\u001b[39;00m alpha \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\matplotlib\\colors.py:377\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 377\u001b[0m     rgba \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([to_rgba(cc) \u001b[39mfor\u001b[39;00m cc \u001b[39min\u001b[39;00m c])\n\u001b[0;32m    379\u001b[0m \u001b[39mif\u001b[39;00m alpha \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\matplotlib\\colors.py:187\u001b[0m, in \u001b[0;36mto_rgba\u001b[1;34m(c, alpha)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[39mif\u001b[39;00m rgba \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# Suppress exception chaining of cache lookup failure.\u001b[39;00m\n\u001b[1;32m--> 187\u001b[0m     rgba \u001b[39m=\u001b[39m _to_rgba_no_colorcycle(c, alpha)\n\u001b[0;32m    188\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\matplotlib\\colors.py:269\u001b[0m, in \u001b[0;36m_to_rgba_no_colorcycle\u001b[1;34m(c, alpha)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39miterable(c):\n\u001b[1;32m--> 269\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid RGBA argument: \u001b[39m\u001b[39m{\u001b[39;00morig_c\u001b[39m!r}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    270\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(c) \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m3\u001b[39m, \u001b[39m4\u001b[39m]:\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid RGBA argument: 1",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Marta\\Desktop\\Studia\\CDV\\IV semestr 2022L\\Wykorzystanie Pythona w uczeniu maszynowym\\ml_project\\project\\ML_PROJECT_2022\\notebooks\\grid-search.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Marta/Desktop/Studia/CDV/IV%20semestr%202022L/Wykorzystanie%20Pythona%20w%20uczeniu%20maszynowym/ml_project/project/ML_PROJECT_2022/notebooks/grid-search.ipynb#ch0000028?line=0'>1</a>\u001b[0m plt\u001b[39m.\u001b[39;49mscatter(X_kpca[:,\u001b[39m0\u001b[39;49m], X_kpca[:,\u001b[39m1\u001b[39;49m], color\u001b[39m=\u001b[39;49my[\u001b[39m0\u001b[39;49m])\n",
      "File \u001b[1;32mc:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\matplotlib\\pyplot.py:2807\u001b[0m, in \u001b[0;36mscatter\u001b[1;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[0;32m   2802\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39mscatter)\n\u001b[0;32m   2803\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mscatter\u001b[39m(\n\u001b[0;32m   2804\u001b[0m         x, y, s\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, c\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, marker\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, cmap\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, norm\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   2805\u001b[0m         vmin\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, vmax\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, alpha\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, linewidths\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m,\n\u001b[0;32m   2806\u001b[0m         edgecolors\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, plotnonfinite\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m-> 2807\u001b[0m     __ret \u001b[39m=\u001b[39m gca()\u001b[39m.\u001b[39mscatter(\n\u001b[0;32m   2808\u001b[0m         x, y, s\u001b[39m=\u001b[39ms, c\u001b[39m=\u001b[39mc, marker\u001b[39m=\u001b[39mmarker, cmap\u001b[39m=\u001b[39mcmap, norm\u001b[39m=\u001b[39mnorm,\n\u001b[0;32m   2809\u001b[0m         vmin\u001b[39m=\u001b[39mvmin, vmax\u001b[39m=\u001b[39mvmax, alpha\u001b[39m=\u001b[39malpha, linewidths\u001b[39m=\u001b[39mlinewidths,\n\u001b[0;32m   2810\u001b[0m         edgecolors\u001b[39m=\u001b[39medgecolors, plotnonfinite\u001b[39m=\u001b[39mplotnonfinite,\n\u001b[0;32m   2811\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m({\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m: data} \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {}), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   2812\u001b[0m     sci(__ret)\n\u001b[0;32m   2813\u001b[0m     \u001b[39mreturn\u001b[39;00m __ret\n",
      "File \u001b[1;32mc:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\matplotlib\\__init__.py:1412\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1409\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m   1410\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(ax, \u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   1411\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1412\u001b[0m         \u001b[39mreturn\u001b[39;00m func(ax, \u001b[39m*\u001b[39m\u001b[39mmap\u001b[39m(sanitize_sequence, args), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1414\u001b[0m     bound \u001b[39m=\u001b[39m new_sig\u001b[39m.\u001b[39mbind(ax, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1415\u001b[0m     auto_label \u001b[39m=\u001b[39m (bound\u001b[39m.\u001b[39marguments\u001b[39m.\u001b[39mget(label_namer)\n\u001b[0;32m   1416\u001b[0m                   \u001b[39mor\u001b[39;00m bound\u001b[39m.\u001b[39mkwargs\u001b[39m.\u001b[39mget(label_namer))\n",
      "File \u001b[1;32mc:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\matplotlib\\axes\\_axes.py:4387\u001b[0m, in \u001b[0;36mAxes.scatter\u001b[1;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[0;32m   4384\u001b[0m \u001b[39mif\u001b[39;00m edgecolors \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   4385\u001b[0m     orig_edgecolor \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39medgecolor\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m   4386\u001b[0m c, colors, edgecolors \u001b[39m=\u001b[39m \\\n\u001b[1;32m-> 4387\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parse_scatter_color_args(\n\u001b[0;32m   4388\u001b[0m         c, edgecolors, kwargs, x\u001b[39m.\u001b[39;49msize,\n\u001b[0;32m   4389\u001b[0m         get_next_color_func\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_patches_for_fill\u001b[39m.\u001b[39;49mget_next_color)\n\u001b[0;32m   4391\u001b[0m \u001b[39mif\u001b[39;00m plotnonfinite \u001b[39mand\u001b[39;00m colors \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   4392\u001b[0m     c \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mma\u001b[39m.\u001b[39mmasked_invalid(c)\n",
      "File \u001b[1;32mc:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\matplotlib\\axes\\_axes.py:4162\u001b[0m, in \u001b[0;36mAxes._parse_scatter_color_args\u001b[1;34m(c, edgecolors, kwargs, xsize, get_next_color_func)\u001b[0m\n\u001b[0;32m   4160\u001b[0m     mcolors\u001b[39m.\u001b[39mto_rgba_array(kwcolor)\n\u001b[0;32m   4161\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 4162\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   4163\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcolor\u001b[39m\u001b[39m'\u001b[39m\u001b[39m kwarg must be a color or sequence of color \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   4164\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mspecs.  For a sequence of values to be color-mapped, use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   4165\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mthe \u001b[39m\u001b[39m'\u001b[39m\u001b[39mc\u001b[39m\u001b[39m'\u001b[39m\u001b[39m argument instead.\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   4166\u001b[0m \u001b[39mif\u001b[39;00m edgecolors \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   4167\u001b[0m     edgecolors \u001b[39m=\u001b[39m kwcolor\n",
      "\u001b[1;31mValueError\u001b[0m: 'color' kwarg must be a color or sequence of color specs.  For a sequence of values to be color-mapped, use the 'c' argument instead."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X_kpca[:,0], X_kpca[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9490, 510)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normal distribution test\n",
    "\n",
    "from scipy.stats import normaltest\n",
    "\n",
    "stat, p = normaltest(X)\n",
    "stat, p\n",
    "\n",
    "normal = 0\n",
    "not_normal = 0\n",
    "\n",
    "# hipothesis : x comes from a normal distribution\n",
    "\n",
    "for i in p:\n",
    "    if i < 0.05:\n",
    "        not_normal += 1 # hypothesis can be rejected\n",
    "    else:\n",
    "        normal += 1 # hypothesis can not be rejected\n",
    "\n",
    "normal, not_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82425654, 0.65432097, 0.98708188, ..., 0.08635164, 0.4635971 ,\n",
       "       0.80054311])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standarization\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_scal = scaler.fit_transform(pd.DataFrame(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_copy = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rem = ho.removing_iqr(pd.DataFrame(X_copy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "contamination = X_rem.sum().sum() / (X_rem.shape[0] * X_rem.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007063386666666667"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contamination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked = ho.mask_outliers(X_copy, X_rem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaced = ho.replace_missing_values(masked, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig, (ax1) = plt.subplots(ncols=1, figsize=(10, 8))\n",
    "ax1.set_title('Distribution after outliers')\n",
    "\n",
    "for i in replaced:\n",
    "    sns.kdeplot(replaced[i], ax=ax1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_binar = binarize(y)\n",
    "y = pd.DataFrame(np.ravel(y_binar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PCA that will retain 95% of the variance\n",
    "pca = PCA(n_components=0.95, whiten=True)\n",
    "\n",
    "# Conduct PCA\n",
    "X_pca = pca.fit_transform(replaced)\n",
    "X_pca = pd.DataFrame(X_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>9990</th>\n",
       "      <th>9991</th>\n",
       "      <th>9992</th>\n",
       "      <th>9993</th>\n",
       "      <th>9994</th>\n",
       "      <th>9995</th>\n",
       "      <th>9996</th>\n",
       "      <th>9997</th>\n",
       "      <th>9998</th>\n",
       "      <th>9999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>304.3610</td>\n",
       "      <td>-436.590</td>\n",
       "      <td>-33854.769</td>\n",
       "      <td>-96571.569</td>\n",
       "      <td>-15086.947</td>\n",
       "      <td>-794.409</td>\n",
       "      <td>-442.859</td>\n",
       "      <td>304.248</td>\n",
       "      <td>-202.411</td>\n",
       "      <td>-506.852</td>\n",
       "      <td>...</td>\n",
       "      <td>95.294</td>\n",
       "      <td>-3.936</td>\n",
       "      <td>-251.812</td>\n",
       "      <td>256.429</td>\n",
       "      <td>-473.661</td>\n",
       "      <td>-1398.604</td>\n",
       "      <td>42.638</td>\n",
       "      <td>771.185</td>\n",
       "      <td>-191.123</td>\n",
       "      <td>1356.137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.0470</td>\n",
       "      <td>90.087</td>\n",
       "      <td>-154.747</td>\n",
       "      <td>-4116.486</td>\n",
       "      <td>38365.133</td>\n",
       "      <td>-589.309</td>\n",
       "      <td>1115.367</td>\n",
       "      <td>274.199</td>\n",
       "      <td>814.953</td>\n",
       "      <td>167.272</td>\n",
       "      <td>...</td>\n",
       "      <td>-176.341</td>\n",
       "      <td>-426.238</td>\n",
       "      <td>-542.428</td>\n",
       "      <td>99.147</td>\n",
       "      <td>-102.309</td>\n",
       "      <td>-277.948</td>\n",
       "      <td>-98.859</td>\n",
       "      <td>-1163.779</td>\n",
       "      <td>265.231</td>\n",
       "      <td>-992.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>272.1680</td>\n",
       "      <td>-201.736</td>\n",
       "      <td>4212.592</td>\n",
       "      <td>-9123.655</td>\n",
       "      <td>-35422.458</td>\n",
       "      <td>-1029.249</td>\n",
       "      <td>-506.290</td>\n",
       "      <td>-476.856</td>\n",
       "      <td>-570.731</td>\n",
       "      <td>-161.288</td>\n",
       "      <td>...</td>\n",
       "      <td>321.426</td>\n",
       "      <td>-376.033</td>\n",
       "      <td>142.834</td>\n",
       "      <td>920.958</td>\n",
       "      <td>-122.525</td>\n",
       "      <td>-174.304</td>\n",
       "      <td>-137.612</td>\n",
       "      <td>-1571.473</td>\n",
       "      <td>678.323</td>\n",
       "      <td>1020.263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>170.0070</td>\n",
       "      <td>68.736</td>\n",
       "      <td>48662.079</td>\n",
       "      <td>29735.235</td>\n",
       "      <td>-13903.955</td>\n",
       "      <td>895.081</td>\n",
       "      <td>-257.748</td>\n",
       "      <td>-811.058</td>\n",
       "      <td>-691.561</td>\n",
       "      <td>-31.439</td>\n",
       "      <td>...</td>\n",
       "      <td>-409.919</td>\n",
       "      <td>400.946</td>\n",
       "      <td>313.270</td>\n",
       "      <td>123.172</td>\n",
       "      <td>1786.962</td>\n",
       "      <td>147.637</td>\n",
       "      <td>31.433</td>\n",
       "      <td>-784.719</td>\n",
       "      <td>573.433</td>\n",
       "      <td>1454.415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86.7970</td>\n",
       "      <td>180.052</td>\n",
       "      <td>-49643.545</td>\n",
       "      <td>2515.406</td>\n",
       "      <td>26206.315</td>\n",
       "      <td>-407.453</td>\n",
       "      <td>-189.416</td>\n",
       "      <td>-53.664</td>\n",
       "      <td>-159.507</td>\n",
       "      <td>-42.291</td>\n",
       "      <td>...</td>\n",
       "      <td>-101.761</td>\n",
       "      <td>-424.898</td>\n",
       "      <td>37.254</td>\n",
       "      <td>-337.431</td>\n",
       "      <td>423.691</td>\n",
       "      <td>14.240</td>\n",
       "      <td>267.352</td>\n",
       "      <td>-234.560</td>\n",
       "      <td>-213.804</td>\n",
       "      <td>873.391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3745</th>\n",
       "      <td>338.5390</td>\n",
       "      <td>-98.216</td>\n",
       "      <td>-37488.883</td>\n",
       "      <td>-2346.403</td>\n",
       "      <td>-291.325</td>\n",
       "      <td>553.155</td>\n",
       "      <td>1041.511</td>\n",
       "      <td>391.664</td>\n",
       "      <td>1016.730</td>\n",
       "      <td>49.772</td>\n",
       "      <td>...</td>\n",
       "      <td>350.501</td>\n",
       "      <td>-607.873</td>\n",
       "      <td>430.407</td>\n",
       "      <td>-469.737</td>\n",
       "      <td>68.670</td>\n",
       "      <td>328.636</td>\n",
       "      <td>105.448</td>\n",
       "      <td>-368.834</td>\n",
       "      <td>378.017</td>\n",
       "      <td>-253.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3746</th>\n",
       "      <td>105.5110</td>\n",
       "      <td>-167.468</td>\n",
       "      <td>54447.468</td>\n",
       "      <td>-38055.924</td>\n",
       "      <td>-12394.035</td>\n",
       "      <td>711.218</td>\n",
       "      <td>100.459</td>\n",
       "      <td>-1377.005</td>\n",
       "      <td>-171.175</td>\n",
       "      <td>-325.444</td>\n",
       "      <td>...</td>\n",
       "      <td>4.759</td>\n",
       "      <td>-9.079</td>\n",
       "      <td>104.333</td>\n",
       "      <td>4.676</td>\n",
       "      <td>-1069.879</td>\n",
       "      <td>-92.252</td>\n",
       "      <td>86.110</td>\n",
       "      <td>-4.935</td>\n",
       "      <td>433.674</td>\n",
       "      <td>-355.118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3747</th>\n",
       "      <td>93.1860</td>\n",
       "      <td>-155.288</td>\n",
       "      <td>-16555.534</td>\n",
       "      <td>-10605.421</td>\n",
       "      <td>-3027.792</td>\n",
       "      <td>-80.498</td>\n",
       "      <td>-2201.598</td>\n",
       "      <td>-49.392</td>\n",
       "      <td>-848.946</td>\n",
       "      <td>-252.714</td>\n",
       "      <td>...</td>\n",
       "      <td>-342.855</td>\n",
       "      <td>-151.956</td>\n",
       "      <td>7.386</td>\n",
       "      <td>564.910</td>\n",
       "      <td>613.541</td>\n",
       "      <td>-570.735</td>\n",
       "      <td>-5.810</td>\n",
       "      <td>797.659</td>\n",
       "      <td>-289.170</td>\n",
       "      <td>-91.306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3748</th>\n",
       "      <td>103.6948</td>\n",
       "      <td>98.182</td>\n",
       "      <td>-39429.721</td>\n",
       "      <td>26215.357</td>\n",
       "      <td>-1465.352</td>\n",
       "      <td>-340.496</td>\n",
       "      <td>-992.109</td>\n",
       "      <td>990.646</td>\n",
       "      <td>140.943</td>\n",
       "      <td>-281.100</td>\n",
       "      <td>...</td>\n",
       "      <td>200.827</td>\n",
       "      <td>-1445.572</td>\n",
       "      <td>-39.879</td>\n",
       "      <td>421.075</td>\n",
       "      <td>-191.389</td>\n",
       "      <td>-538.616</td>\n",
       "      <td>141.365</td>\n",
       "      <td>552.974</td>\n",
       "      <td>310.130</td>\n",
       "      <td>207.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3749</th>\n",
       "      <td>-169.3940</td>\n",
       "      <td>127.276</td>\n",
       "      <td>-24661.781</td>\n",
       "      <td>37020.744</td>\n",
       "      <td>-17491.827</td>\n",
       "      <td>46.510</td>\n",
       "      <td>560.459</td>\n",
       "      <td>155.117</td>\n",
       "      <td>-217.523</td>\n",
       "      <td>-448.290</td>\n",
       "      <td>...</td>\n",
       "      <td>-87.249</td>\n",
       "      <td>-419.265</td>\n",
       "      <td>224.068</td>\n",
       "      <td>-75.648</td>\n",
       "      <td>-302.584</td>\n",
       "      <td>-164.119</td>\n",
       "      <td>19.465</td>\n",
       "      <td>-841.065</td>\n",
       "      <td>-973.910</td>\n",
       "      <td>-803.150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3750 rows × 10000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0        1          2          3          4         5         6     \\\n",
       "0     304.3610 -436.590 -33854.769 -96571.569 -15086.947  -794.409  -442.859   \n",
       "1      54.0470   90.087   -154.747  -4116.486  38365.133  -589.309  1115.367   \n",
       "2     272.1680 -201.736   4212.592  -9123.655 -35422.458 -1029.249  -506.290   \n",
       "3     170.0070   68.736  48662.079  29735.235 -13903.955   895.081  -257.748   \n",
       "4      86.7970  180.052 -49643.545   2515.406  26206.315  -407.453  -189.416   \n",
       "...        ...      ...        ...        ...        ...       ...       ...   \n",
       "3745  338.5390  -98.216 -37488.883  -2346.403   -291.325   553.155  1041.511   \n",
       "3746  105.5110 -167.468  54447.468 -38055.924 -12394.035   711.218   100.459   \n",
       "3747   93.1860 -155.288 -16555.534 -10605.421  -3027.792   -80.498 -2201.598   \n",
       "3748  103.6948   98.182 -39429.721  26215.357  -1465.352  -340.496  -992.109   \n",
       "3749 -169.3940  127.276 -24661.781  37020.744 -17491.827    46.510   560.459   \n",
       "\n",
       "          7         8        9     ...     9990      9991     9992     9993  \\\n",
       "0      304.248  -202.411 -506.852  ...   95.294    -3.936 -251.812  256.429   \n",
       "1      274.199   814.953  167.272  ... -176.341  -426.238 -542.428   99.147   \n",
       "2     -476.856  -570.731 -161.288  ...  321.426  -376.033  142.834  920.958   \n",
       "3     -811.058  -691.561  -31.439  ... -409.919   400.946  313.270  123.172   \n",
       "4      -53.664  -159.507  -42.291  ... -101.761  -424.898   37.254 -337.431   \n",
       "...        ...       ...      ...  ...      ...       ...      ...      ...   \n",
       "3745   391.664  1016.730   49.772  ...  350.501  -607.873  430.407 -469.737   \n",
       "3746 -1377.005  -171.175 -325.444  ...    4.759    -9.079  104.333    4.676   \n",
       "3747   -49.392  -848.946 -252.714  ... -342.855  -151.956    7.386  564.910   \n",
       "3748   990.646   140.943 -281.100  ...  200.827 -1445.572  -39.879  421.075   \n",
       "3749   155.117  -217.523 -448.290  ...  -87.249  -419.265  224.068  -75.648   \n",
       "\n",
       "          9994      9995     9996      9997     9998      9999  \n",
       "0     -473.661 -1398.604   42.638   771.185 -191.123  1356.137  \n",
       "1     -102.309  -277.948  -98.859 -1163.779  265.231  -992.056  \n",
       "2     -122.525  -174.304 -137.612 -1571.473  678.323  1020.263  \n",
       "3     1786.962   147.637   31.433  -784.719  573.433  1454.415  \n",
       "4      423.691    14.240  267.352  -234.560 -213.804   873.391  \n",
       "...        ...       ...      ...       ...      ...       ...  \n",
       "3745    68.670   328.636  105.448  -368.834  378.017  -253.044  \n",
       "3746 -1069.879   -92.252   86.110    -4.935  433.674  -355.118  \n",
       "3747   613.541  -570.735   -5.810   797.659 -289.170   -91.306  \n",
       "3748  -191.389  -538.616  141.365   552.974  310.130   207.084  \n",
       "3749  -302.584  -164.119   19.465  -841.065 -973.910  -803.150  \n",
       "\n",
       "[3750 rows x 10000 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replaced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 9974)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import normaltest\n",
    "\n",
    "stat, p = normaltest(replaced)\n",
    "stat, p\n",
    "\n",
    "normal = 0\n",
    "not_normal = 0\n",
    "\n",
    "# hypothesis : x comes from a normal distribution\n",
    "\n",
    "for i in p:\n",
    "    if i < 0.05:\n",
    "        not_normal += 1 # hypothesis can be rejected\n",
    "    else:\n",
    "        normal += 1 # hypothesis can not be rejected\n",
    "\n",
    "normal, not_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[(\"classifier\", LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'svm' : {\n",
    "        'model' : SVC(kernel='linear'),\n",
    "        'params' : {\n",
    "            'C' : [1, 10, 20],\n",
    "            'gamma' : ['scale', 'auto'],\n",
    "            'class_weight' : ['balanced']\n",
    "        }\n",
    "    },\n",
    "    'random_forest' : {\n",
    "        'model' : RandomForestClassifier(),\n",
    "        'params' : {\n",
    "            'n_estimators' : [10, 100, 1000],\n",
    "            'max_features' : ['auto', 'sqrt', 'log2', 'none'],\n",
    "            'class_weight' : ['balanced']\n",
    "        }\n",
    "    },\n",
    "    'logistic_regression' : {\n",
    "        'model' : LogisticRegression(solver = 'liblinear', multi_class='auto'),\n",
    "        'params' : {\n",
    "            'C' : np.linspace(1, 5, 10),\n",
    "            'penalty' : ['none', 'l1', 'l2', 'elasticnet'],\n",
    "            'class_weight' : ['balanced']\n",
    "        }\n",
    "    },\n",
    "    'bernoulliNB' : {\n",
    "        'model' : BernoulliNB(),\n",
    "        'params' : {\n",
    "            'alpha' : np.linspace(1, 10, 100)\n",
    "        }\n",
    "    },\n",
    "    'KN_neighbors' : {\n",
    "        'model' : KNeighborsClassifier(),\n",
    "        'params' : {\n",
    "            'weights' : ['uniform', 'distance'],\n",
    "            'algorithm' : ['auto', 'kd-tree', 'brute'],\n",
    "            'n_neighbors' : [3, 5, 7, 9, 11, 13, 15, 17, 19, 21]\n",
    "        }\n",
    "    },\n",
    "    'MLP' : {\n",
    "        'model' : MLPClassifier(),\n",
    "        'params' : {}\n",
    "    },\n",
    "    'Decision_tree' : {\n",
    "        'model' : DecisionTreeClassifier(),\n",
    "        'params' : {\n",
    "            'criterion' : ['gini', 'entropy', 'log_loss'],\n",
    "            'splitter' : ['best', 'random'],\n",
    "            'max_features' : ['auto', 'sqrt', 'log2', 'none'],\n",
    "            'class_weight' : ['balanced']\n",
    "        }\n",
    "    },\n",
    "    'extra_tree' : {\n",
    "        'model' : ExtraTreesClassifier(),\n",
    "        'params' : {\n",
    "            'n_estimators' : [10, 100, 1000],\n",
    "            'criterion' : ['gini', 'entropy', 'log_loss'],\n",
    "            'max_features' : ['sqrt', 'log2', 'none'],\n",
    "            'class_weight' : ['balanced']\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\numpy\\core\\function_base.py:277: RuntimeWarning: overflow encountered in power\n",
      "  return _nx.power(base, y)\n"
     ]
    }
   ],
   "source": [
    "search_space = [{\"classifier\" : [LogisticRegression()],\n",
    "                 \"classifier__solver\" : ['sag', 'saga', 'liblinear'],\n",
    "                \"classifier__penalty\" : ['l1', 'l2', 'elasticnet', 'none'],\n",
    "                \"classifier__C\" : [np.logspace(1, 4, 10)],\n",
    "                \"classifier__class_weight\" : ['balanced', {\"0\" : 0.1, \"1\" : 0.9}]},\n",
    "                {\"classifier\" : [BernoulliNB()],\n",
    "                \"classifier__alpha\" : [np.linspace(1, 10, 100)]},\n",
    "                {\"classifier\" : [RandomForestClassifier()],\n",
    "                \"classifier__n_estimators\" : [10, 100, 1000],\n",
    "                \"classifier__criterion\" : ['gini', 'entropy', 'log_loss'],\n",
    "                \"classifier__max_features\" : ['auto', 'sqrt', 'log2', 'none'],\n",
    "                \"classifier__class_weight\" : ['balanced', [{0 : 1}, {1 : 9}]]},\n",
    "                {\"classifier\" : [KNeighborsClassifier()],\n",
    "                \"classifier__weights\" : ['uniform', 'distance'],\n",
    "                \"classifier__algorithm\" : ['auto', 'ball-tree', 'kd-tree', 'brute'],\n",
    "                \"classifier__n_neighbors\" : [np.linspace(1, 11, 6)]},\n",
    "                {\"classifier\" : [SVC()],\n",
    "                \"classifier__C\" : [np.logspace(1, 10000, 1000)],\n",
    "                \"classifier__class_weight\" : ['balanced', [{0 : 1}, {1 : 9}]]},\n",
    "                {\"classifier\" : [MLPClassifier()]},\n",
    "                {\"classifier\" : [DecisionTreeClassifier()],\n",
    "                \"classifier__criterion\" : ['gini', 'entropy', 'log_loss'],\n",
    "                \"classifier__splitter\" : ['best', 'random'],\n",
    "                \"classifier__max_features\" : ['auto', 'sqrt', 'log2', 'none'],\n",
    "                \"classifier__class_weight\" : ['balanced', [{0 : 1}, {1 : 9}]]},\n",
    "                {\"classifier\" : [ExtraTreesClassifier()],\n",
    "                \"classifier__n_estimators\" : [10, 100, 1000],\n",
    "                \"classifier__criterion\" : ['gini', 'entropy', 'log_loss'],\n",
    "                \"classifier__max_features\" : ['sqrt', 'log2', 'none'],\n",
    "                \"classifier__class_weight\" : ['balanced', [{0 : 1}, {1 : 9}]]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "splits = 3\n",
    "n_repeats = 10\n",
    "rskf = RepeatedStratifiedKFold(n_splits=splits, n_repeats=n_repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "600 fits failed out of a total of 1200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "300 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 198, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 437, in _fit\n",
      "    self._check_algorithm_metric()\n",
      "  File \"c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 352, in _check_algorithm_metric\n",
      "    raise ValueError(\"unrecognized algorithm: '%s'\" % self.algorithm)\n",
      "ValueError: unrecognized algorithm: 'ball-tree'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "300 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 198, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 437, in _fit\n",
      "    self._check_algorithm_metric()\n",
      "  File \"c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 352, in _check_algorithm_metric\n",
      "    raise ValueError(\"unrecognized algorithm: '%s'\" % self.algorithm)\n",
      "ValueError: unrecognized algorithm: 'kd-tree'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.50435219 0.50435219 0.49995694 0.49995694 0.4994077  0.4994077\n",
      " 0.49975301 0.49975301 0.49995069 0.49995069        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.50435219 0.50435219 0.49995694 0.49995694 0.4994077  0.4994077\n",
      " 0.49975301 0.49975301 0.49995069 0.49995069]\n",
      "  warnings.warn(\n",
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "720 fits failed out of a total of 1440.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "360 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 281, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "360 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 352, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.49951622 0.50293389 0.50369832 0.50918239 0.5074743  0.4981546\n",
      "        nan        nan 0.49190215 0.49664658 0.50321023 0.49516672\n",
      " 0.49637821 0.49913836        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.50295832 0.51025918 0.50471798 0.49505805 0.49612588 0.50163801\n",
      "        nan        nan 0.49386799 0.5087591  0.50679682 0.5074152\n",
      " 0.50413057 0.49527114        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "900 fits failed out of a total of 1620.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "540 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 187, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 281, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "360 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 187, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 352, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.49945701 0.5        0.5        0.49916027 0.5        0.5\n",
      "        nan        nan        nan 0.49951196 0.5        0.5\n",
      " 0.50035126 0.5        0.5               nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.50196496 0.5        0.5\n",
      " 0.50168571 0.5        0.5               nan        nan        nan\n",
      " 0.50010456 0.5        0.5        0.5003896  0.5        0.5\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3)\n",
    "\n",
    "for model_name, mp in model_params.items():\n",
    "  clf = GridSearchCV(mp['model'], mp['params'], scoring = 'balanced_accuracy', cv = cv)\n",
    "  clf.fit(X_pca, y.values.flatten())\n",
    "  scores.append({\n",
    "      'model': model_name,\n",
    "      'best_score': clf.best_score_,\n",
    "      'best_params': clf.best_params_\n",
    "  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': 'KN_neighbors',\n",
       "  'best_score': 0.504352186550435,\n",
       "  'best_params': {'algorithm': 'auto',\n",
       "   'n_neighbors': 3,\n",
       "   'weights': 'uniform'}},\n",
       " {'model': 'MLP', 'best_score': 0.4988623231685379, 'best_params': {}},\n",
       " {'model': 'Decision_tree',\n",
       "  'best_score': 0.5102591770058341,\n",
       "  'best_params': {'class_weight': {0: 1, 1: 9},\n",
       "   'criterion': 'gini',\n",
       "   'max_features': 'auto',\n",
       "   'splitter': 'random'}},\n",
       " {'model': 'extra_tree',\n",
       "  'best_score': 0.5019649613424767,\n",
       "  'best_params': {'class_weight': {0: 1, 1: 9},\n",
       "   'criterion': 'gini',\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 10}}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "scoring = [\"balanced_accuracy\", \"f1_weighted\"]\n",
    "\n",
    "search = GridSearchCV(pipe, search_space, cv=rskf, scoring=\"balanced_accuracy\", refit=True, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 30 folds for each of 210 candidates, totalling 6300 fits\n",
      "[CV 1/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 6/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 7/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 8/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 9/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 10/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 11/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 12/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 13/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 14/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 15/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 16/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 17/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 18/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 19/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 20/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 21/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 22/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 23/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 24/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 25/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 26/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 27/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 28/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 29/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 30/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 6/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 7/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 8/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 9/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 10/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 11/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 12/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 13/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 14/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 15/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 16/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 17/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 18/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 19/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 20/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 21/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 22/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 23/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 24/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 25/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 26/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 27/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 28/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 29/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 30/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 6/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 7/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 8/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 9/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 10/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 11/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 12/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 13/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 14/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 15/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 16/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 17/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 18/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 19/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 20/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 21/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 22/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 23/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 24/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 25/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 26/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 27/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 28/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 29/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 30/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 6/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 7/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 8/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 9/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 10/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 11/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 12/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 13/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 14/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 15/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 16/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 17/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 18/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 19/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 20/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 21/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 22/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 23/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 24/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 25/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 26/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 27/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 28/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 29/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 30/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 6/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 7/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 8/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 9/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 10/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 11/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 12/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 13/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 14/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 15/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 16/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 17/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 18/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 19/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 20/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 21/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 22/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 23/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 24/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 25/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 26/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 27/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 28/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 29/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 30/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 6/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 7/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 8/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 9/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 10/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 11/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 12/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 13/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 14/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 15/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 16/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 17/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 18/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 19/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 20/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 21/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 22/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 23/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 24/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 25/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 26/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 27/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 28/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 29/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 30/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 6/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 7/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 8/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 9/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 10/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 11/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 12/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 13/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 14/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 15/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 16/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 17/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 18/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 19/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 20/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 21/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 22/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 23/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 24/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 25/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 26/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 27/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 28/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 29/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 30/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 6/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 7/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 8/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 9/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 10/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 11/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 12/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 13/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 14/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 15/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 16/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 17/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 18/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 19/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 20/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 21/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 22/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 23/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 24/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 25/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 26/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 27/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 28/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 29/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 30/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 6/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 7/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 8/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 9/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 10/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 11/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 12/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 13/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 14/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 15/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 16/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 17/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 18/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 19/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 20/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 21/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 22/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 23/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 24/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 25/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 26/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 27/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 28/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 29/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 30/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 6/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 7/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 8/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 9/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 10/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 11/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 12/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 13/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 14/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 15/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 16/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 17/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 18/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 19/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 20/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 21/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 22/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 23/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 24/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 25/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 26/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 27/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 28/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 29/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 30/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 6/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 7/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 8/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 9/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 10/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 11/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 12/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 13/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 14/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 15/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 16/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 17/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 18/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 19/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 20/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 21/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 22/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 23/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 24/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 25/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 26/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 27/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 28/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 29/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 30/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 6/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 7/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 8/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 9/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 10/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 11/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 12/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 13/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 14/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 15/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 16/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 17/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 18/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 19/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 20/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 21/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 22/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 23/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 24/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 25/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 26/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 27/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 28/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 29/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 30/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight=balanced, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 6/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 7/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 8/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 9/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 10/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 11/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 12/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 13/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 14/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 15/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 16/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 17/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 18/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 19/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 20/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 21/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 22/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 23/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 24/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 25/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 26/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 27/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 28/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 29/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 30/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 6/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 7/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 8/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 9/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 10/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 11/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 12/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 13/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 14/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 15/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 16/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 17/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 18/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 19/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 20/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 21/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 22/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 23/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 24/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 25/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 26/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 27/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 28/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 29/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 30/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 6/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 7/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 8/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 9/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 10/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 11/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 12/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 13/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 14/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 15/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 16/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 17/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 18/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 19/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 20/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 21/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 22/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 23/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 24/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 25/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 26/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 27/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 28/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 29/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 30/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l1, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 6/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 7/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 8/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 9/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 10/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 11/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 12/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 13/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 14/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 15/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 16/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 17/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 18/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 19/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 20/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 21/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 22/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 23/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 24/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 25/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 26/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 27/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 28/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 29/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 30/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 6/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 7/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 8/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 9/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 10/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 11/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 12/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 13/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 14/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 15/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 16/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 17/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 18/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 19/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 20/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 21/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 22/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 23/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 24/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 25/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 26/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 27/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 28/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 29/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 30/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 6/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 7/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 8/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 9/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 10/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 11/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 12/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 13/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 14/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 15/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 16/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 17/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 18/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 19/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 20/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 21/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 22/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 23/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 24/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 25/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 26/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 27/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 28/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 29/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 30/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=l2, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 6/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 7/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 8/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 9/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 10/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 11/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 12/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 13/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 14/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 15/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 16/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 17/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 18/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 19/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 20/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 21/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 22/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 23/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 24/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 25/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 26/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 27/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 28/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 29/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 30/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 6/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 7/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 8/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 9/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 10/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 11/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 12/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 13/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 14/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 15/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 16/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 17/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 18/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 19/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 20/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 21/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 22/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 23/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 24/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 25/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 26/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 27/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 28/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 29/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 30/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 6/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 7/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 8/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 9/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 10/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 11/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 12/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 13/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 14/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 15/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 16/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 17/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 18/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 19/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 20/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 21/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 22/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 23/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 24/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 25/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 26/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 27/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 28/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 29/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 30/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=elasticnet, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 6/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 7/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 8/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 9/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 10/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 11/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 12/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 13/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 14/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 15/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 16/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 17/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 18/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 19/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 20/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 21/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 22/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 23/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 24/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 25/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 26/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 27/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 28/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 29/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 30/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 6/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 7/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 8/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 9/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 10/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 11/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 12/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 13/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 14/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 15/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 16/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 17/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 18/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 19/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 20/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 21/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 22/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 23/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 24/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 25/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 26/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 27/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 28/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 29/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 30/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 6/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 7/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 8/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 9/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 10/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 11/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 12/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 13/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 14/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 15/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 16/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 17/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 18/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 19/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 20/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 21/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 22/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 23/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 24/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 25/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 26/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 27/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 28/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 29/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 30/30] END classifier=LogisticRegression(), classifier__C=[   10.            21.5443469     46.41588834   100.\n",
      "   215.443469     464.15888336  1000.          2154.43469003\n",
      "  4641.58883361 10000.        ], classifier__class_weight={'0': 0.1, '1': 0.9}, classifier__penalty=none, classifier__solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/30] END classifier=BernoulliNB(), classifier__alpha=[ 1.          1.09090909  1.18181818  1.27272727  1.36363636  1.45454545\n",
      "  1.54545455  1.63636364  1.72727273  1.81818182  1.90909091  2.\n",
      "  2.09090909  2.18181818  2.27272727  2.36363636  2.45454545  2.54545455\n",
      "  2.63636364  2.72727273  2.81818182  2.90909091  3.          3.09090909\n",
      "  3.18181818  3.27272727  3.36363636  3.45454545  3.54545455  3.63636364\n",
      "  3.72727273  3.81818182  3.90909091  4.          4.09090909  4.18181818\n",
      "  4.27272727  4.36363636  4.45454545  4.54545455  4.63636364  4.72727273\n",
      "  4.81818182  4.90909091  5.          5.09090909  5.18181818  5.27272727\n",
      "  5.36363636  5.45454545  5.54545455  5.63636364  5.72727273  5.81818182\n",
      "  5.90909091  6.          6.09090909  6.18181818  6.27272727  6.36363636\n",
      "  6.45454545  6.54545455  6.63636364  6.72727273  6.81818182  6.90909091\n",
      "  7.          7.09090909  7.18181818  7.27272727  7.36363636  7.45454545\n",
      "  7.54545455  7.63636364  7.72727273  7.81818182  7.90909091  8.\n",
      "  8.09090909  8.18181818  8.27272727  8.36363636  8.45454545  8.54545455\n",
      "  8.63636364  8.72727273  8.81818182  8.90909091  9.          9.09090909\n",
      "  9.18181818  9.27272727  9.36363636  9.45454545  9.54545455  9.63636364\n",
      "  9.72727273  9.81818182  9.90909091 10.        ];, score=nan total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/30] END classifier=BernoulliNB(), classifier__alpha=[ 1.          1.09090909  1.18181818  1.27272727  1.36363636  1.45454545\n",
      "  1.54545455  1.63636364  1.72727273  1.81818182  1.90909091  2.\n",
      "  2.09090909  2.18181818  2.27272727  2.36363636  2.45454545  2.54545455\n",
      "  2.63636364  2.72727273  2.81818182  2.90909091  3.          3.09090909\n",
      "  3.18181818  3.27272727  3.36363636  3.45454545  3.54545455  3.63636364\n",
      "  3.72727273  3.81818182  3.90909091  4.          4.09090909  4.18181818\n",
      "  4.27272727  4.36363636  4.45454545  4.54545455  4.63636364  4.72727273\n",
      "  4.81818182  4.90909091  5.          5.09090909  5.18181818  5.27272727\n",
      "  5.36363636  5.45454545  5.54545455  5.63636364  5.72727273  5.81818182\n",
      "  5.90909091  6.          6.09090909  6.18181818  6.27272727  6.36363636\n",
      "  6.45454545  6.54545455  6.63636364  6.72727273  6.81818182  6.90909091\n",
      "  7.          7.09090909  7.18181818  7.27272727  7.36363636  7.45454545\n",
      "  7.54545455  7.63636364  7.72727273  7.81818182  7.90909091  8.\n",
      "  8.09090909  8.18181818  8.27272727  8.36363636  8.45454545  8.54545455\n",
      "  8.63636364  8.72727273  8.81818182  8.90909091  9.          9.09090909\n",
      "  9.18181818  9.27272727  9.36363636  9.45454545  9.54545455  9.63636364\n",
      "  9.72727273  9.81818182  9.90909091 10.        ];, score=nan total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/30] END classifier=BernoulliNB(), classifier__alpha=[ 1.          1.09090909  1.18181818  1.27272727  1.36363636  1.45454545\n",
      "  1.54545455  1.63636364  1.72727273  1.81818182  1.90909091  2.\n",
      "  2.09090909  2.18181818  2.27272727  2.36363636  2.45454545  2.54545455\n",
      "  2.63636364  2.72727273  2.81818182  2.90909091  3.          3.09090909\n",
      "  3.18181818  3.27272727  3.36363636  3.45454545  3.54545455  3.63636364\n",
      "  3.72727273  3.81818182  3.90909091  4.          4.09090909  4.18181818\n",
      "  4.27272727  4.36363636  4.45454545  4.54545455  4.63636364  4.72727273\n",
      "  4.81818182  4.90909091  5.          5.09090909  5.18181818  5.27272727\n",
      "  5.36363636  5.45454545  5.54545455  5.63636364  5.72727273  5.81818182\n",
      "  5.90909091  6.          6.09090909  6.18181818  6.27272727  6.36363636\n",
      "  6.45454545  6.54545455  6.63636364  6.72727273  6.81818182  6.90909091\n",
      "  7.          7.09090909  7.18181818  7.27272727  7.36363636  7.45454545\n",
      "  7.54545455  7.63636364  7.72727273  7.81818182  7.90909091  8.\n",
      "  8.09090909  8.18181818  8.27272727  8.36363636  8.45454545  8.54545455\n",
      "  8.63636364  8.72727273  8.81818182  8.90909091  9.          9.09090909\n",
      "  9.18181818  9.27272727  9.36363636  9.45454545  9.54545455  9.63636364\n",
      "  9.72727273  9.81818182  9.90909091 10.        ];, score=nan total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/30] END classifier=BernoulliNB(), classifier__alpha=[ 1.          1.09090909  1.18181818  1.27272727  1.36363636  1.45454545\n",
      "  1.54545455  1.63636364  1.72727273  1.81818182  1.90909091  2.\n",
      "  2.09090909  2.18181818  2.27272727  2.36363636  2.45454545  2.54545455\n",
      "  2.63636364  2.72727273  2.81818182  2.90909091  3.          3.09090909\n",
      "  3.18181818  3.27272727  3.36363636  3.45454545  3.54545455  3.63636364\n",
      "  3.72727273  3.81818182  3.90909091  4.          4.09090909  4.18181818\n",
      "  4.27272727  4.36363636  4.45454545  4.54545455  4.63636364  4.72727273\n",
      "  4.81818182  4.90909091  5.          5.09090909  5.18181818  5.27272727\n",
      "  5.36363636  5.45454545  5.54545455  5.63636364  5.72727273  5.81818182\n",
      "  5.90909091  6.          6.09090909  6.18181818  6.27272727  6.36363636\n",
      "  6.45454545  6.54545455  6.63636364  6.72727273  6.81818182  6.90909091\n",
      "  7.          7.09090909  7.18181818  7.27272727  7.36363636  7.45454545\n",
      "  7.54545455  7.63636364  7.72727273  7.81818182  7.90909091  8.\n",
      "  8.09090909  8.18181818  8.27272727  8.36363636  8.45454545  8.54545455\n",
      "  8.63636364  8.72727273  8.81818182  8.90909091  9.          9.09090909\n",
      "  9.18181818  9.27272727  9.36363636  9.45454545  9.54545455  9.63636364\n",
      "  9.72727273  9.81818182  9.90909091 10.        ];, score=nan total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/30] END classifier=BernoulliNB(), classifier__alpha=[ 1.          1.09090909  1.18181818  1.27272727  1.36363636  1.45454545\n",
      "  1.54545455  1.63636364  1.72727273  1.81818182  1.90909091  2.\n",
      "  2.09090909  2.18181818  2.27272727  2.36363636  2.45454545  2.54545455\n",
      "  2.63636364  2.72727273  2.81818182  2.90909091  3.          3.09090909\n",
      "  3.18181818  3.27272727  3.36363636  3.45454545  3.54545455  3.63636364\n",
      "  3.72727273  3.81818182  3.90909091  4.          4.09090909  4.18181818\n",
      "  4.27272727  4.36363636  4.45454545  4.54545455  4.63636364  4.72727273\n",
      "  4.81818182  4.90909091  5.          5.09090909  5.18181818  5.27272727\n",
      "  5.36363636  5.45454545  5.54545455  5.63636364  5.72727273  5.81818182\n",
      "  5.90909091  6.          6.09090909  6.18181818  6.27272727  6.36363636\n",
      "  6.45454545  6.54545455  6.63636364  6.72727273  6.81818182  6.90909091\n",
      "  7.          7.09090909  7.18181818  7.27272727  7.36363636  7.45454545\n",
      "  7.54545455  7.63636364  7.72727273  7.81818182  7.90909091  8.\n",
      "  8.09090909  8.18181818  8.27272727  8.36363636  8.45454545  8.54545455\n",
      "  8.63636364  8.72727273  8.81818182  8.90909091  9.          9.09090909\n",
      "  9.18181818  9.27272727  9.36363636  9.45454545  9.54545455  9.63636364\n",
      "  9.72727273  9.81818182  9.90909091 10.        ];, score=nan total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/30] END classifier=BernoulliNB(), classifier__alpha=[ 1.          1.09090909  1.18181818  1.27272727  1.36363636  1.45454545\n",
      "  1.54545455  1.63636364  1.72727273  1.81818182  1.90909091  2.\n",
      "  2.09090909  2.18181818  2.27272727  2.36363636  2.45454545  2.54545455\n",
      "  2.63636364  2.72727273  2.81818182  2.90909091  3.          3.09090909\n",
      "  3.18181818  3.27272727  3.36363636  3.45454545  3.54545455  3.63636364\n",
      "  3.72727273  3.81818182  3.90909091  4.          4.09090909  4.18181818\n",
      "  4.27272727  4.36363636  4.45454545  4.54545455  4.63636364  4.72727273\n",
      "  4.81818182  4.90909091  5.          5.09090909  5.18181818  5.27272727\n",
      "  5.36363636  5.45454545  5.54545455  5.63636364  5.72727273  5.81818182\n",
      "  5.90909091  6.          6.09090909  6.18181818  6.27272727  6.36363636\n",
      "  6.45454545  6.54545455  6.63636364  6.72727273  6.81818182  6.90909091\n",
      "  7.          7.09090909  7.18181818  7.27272727  7.36363636  7.45454545\n",
      "  7.54545455  7.63636364  7.72727273  7.81818182  7.90909091  8.\n",
      "  8.09090909  8.18181818  8.27272727  8.36363636  8.45454545  8.54545455\n",
      "  8.63636364  8.72727273  8.81818182  8.90909091  9.          9.09090909\n",
      "  9.18181818  9.27272727  9.36363636  9.45454545  9.54545455  9.63636364\n",
      "  9.72727273  9.81818182  9.90909091 10.        ];, score=nan total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/30] END classifier=BernoulliNB(), classifier__alpha=[ 1.          1.09090909  1.18181818  1.27272727  1.36363636  1.45454545\n",
      "  1.54545455  1.63636364  1.72727273  1.81818182  1.90909091  2.\n",
      "  2.09090909  2.18181818  2.27272727  2.36363636  2.45454545  2.54545455\n",
      "  2.63636364  2.72727273  2.81818182  2.90909091  3.          3.09090909\n",
      "  3.18181818  3.27272727  3.36363636  3.45454545  3.54545455  3.63636364\n",
      "  3.72727273  3.81818182  3.90909091  4.          4.09090909  4.18181818\n",
      "  4.27272727  4.36363636  4.45454545  4.54545455  4.63636364  4.72727273\n",
      "  4.81818182  4.90909091  5.          5.09090909  5.18181818  5.27272727\n",
      "  5.36363636  5.45454545  5.54545455  5.63636364  5.72727273  5.81818182\n",
      "  5.90909091  6.          6.09090909  6.18181818  6.27272727  6.36363636\n",
      "  6.45454545  6.54545455  6.63636364  6.72727273  6.81818182  6.90909091\n",
      "  7.          7.09090909  7.18181818  7.27272727  7.36363636  7.45454545\n",
      "  7.54545455  7.63636364  7.72727273  7.81818182  7.90909091  8.\n",
      "  8.09090909  8.18181818  8.27272727  8.36363636  8.45454545  8.54545455\n",
      "  8.63636364  8.72727273  8.81818182  8.90909091  9.          9.09090909\n",
      "  9.18181818  9.27272727  9.36363636  9.45454545  9.54545455  9.63636364\n",
      "  9.72727273  9.81818182  9.90909091 10.        ];, score=nan total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 8/30] END classifier=BernoulliNB(), classifier__alpha=[ 1.          1.09090909  1.18181818  1.27272727  1.36363636  1.45454545\n",
      "  1.54545455  1.63636364  1.72727273  1.81818182  1.90909091  2.\n",
      "  2.09090909  2.18181818  2.27272727  2.36363636  2.45454545  2.54545455\n",
      "  2.63636364  2.72727273  2.81818182  2.90909091  3.          3.09090909\n",
      "  3.18181818  3.27272727  3.36363636  3.45454545  3.54545455  3.63636364\n",
      "  3.72727273  3.81818182  3.90909091  4.          4.09090909  4.18181818\n",
      "  4.27272727  4.36363636  4.45454545  4.54545455  4.63636364  4.72727273\n",
      "  4.81818182  4.90909091  5.          5.09090909  5.18181818  5.27272727\n",
      "  5.36363636  5.45454545  5.54545455  5.63636364  5.72727273  5.81818182\n",
      "  5.90909091  6.          6.09090909  6.18181818  6.27272727  6.36363636\n",
      "  6.45454545  6.54545455  6.63636364  6.72727273  6.81818182  6.90909091\n",
      "  7.          7.09090909  7.18181818  7.27272727  7.36363636  7.45454545\n",
      "  7.54545455  7.63636364  7.72727273  7.81818182  7.90909091  8.\n",
      "  8.09090909  8.18181818  8.27272727  8.36363636  8.45454545  8.54545455\n",
      "  8.63636364  8.72727273  8.81818182  8.90909091  9.          9.09090909\n",
      "  9.18181818  9.27272727  9.36363636  9.45454545  9.54545455  9.63636364\n",
      "  9.72727273  9.81818182  9.90909091 10.        ];, score=nan total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/30] END classifier=BernoulliNB(), classifier__alpha=[ 1.          1.09090909  1.18181818  1.27272727  1.36363636  1.45454545\n",
      "  1.54545455  1.63636364  1.72727273  1.81818182  1.90909091  2.\n",
      "  2.09090909  2.18181818  2.27272727  2.36363636  2.45454545  2.54545455\n",
      "  2.63636364  2.72727273  2.81818182  2.90909091  3.          3.09090909\n",
      "  3.18181818  3.27272727  3.36363636  3.45454545  3.54545455  3.63636364\n",
      "  3.72727273  3.81818182  3.90909091  4.          4.09090909  4.18181818\n",
      "  4.27272727  4.36363636  4.45454545  4.54545455  4.63636364  4.72727273\n",
      "  4.81818182  4.90909091  5.          5.09090909  5.18181818  5.27272727\n",
      "  5.36363636  5.45454545  5.54545455  5.63636364  5.72727273  5.81818182\n",
      "  5.90909091  6.          6.09090909  6.18181818  6.27272727  6.36363636\n",
      "  6.45454545  6.54545455  6.63636364  6.72727273  6.81818182  6.90909091\n",
      "  7.          7.09090909  7.18181818  7.27272727  7.36363636  7.45454545\n",
      "  7.54545455  7.63636364  7.72727273  7.81818182  7.90909091  8.\n",
      "  8.09090909  8.18181818  8.27272727  8.36363636  8.45454545  8.54545455\n",
      "  8.63636364  8.72727273  8.81818182  8.90909091  9.          9.09090909\n",
      "  9.18181818  9.27272727  9.36363636  9.45454545  9.54545455  9.63636364\n",
      "  9.72727273  9.81818182  9.90909091 10.        ];, score=nan total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 10/30] END classifier=BernoulliNB(), classifier__alpha=[ 1.          1.09090909  1.18181818  1.27272727  1.36363636  1.45454545\n",
      "  1.54545455  1.63636364  1.72727273  1.81818182  1.90909091  2.\n",
      "  2.09090909  2.18181818  2.27272727  2.36363636  2.45454545  2.54545455\n",
      "  2.63636364  2.72727273  2.81818182  2.90909091  3.          3.09090909\n",
      "  3.18181818  3.27272727  3.36363636  3.45454545  3.54545455  3.63636364\n",
      "  3.72727273  3.81818182  3.90909091  4.          4.09090909  4.18181818\n",
      "  4.27272727  4.36363636  4.45454545  4.54545455  4.63636364  4.72727273\n",
      "  4.81818182  4.90909091  5.          5.09090909  5.18181818  5.27272727\n",
      "  5.36363636  5.45454545  5.54545455  5.63636364  5.72727273  5.81818182\n",
      "  5.90909091  6.          6.09090909  6.18181818  6.27272727  6.36363636\n",
      "  6.45454545  6.54545455  6.63636364  6.72727273  6.81818182  6.90909091\n",
      "  7.          7.09090909  7.18181818  7.27272727  7.36363636  7.45454545\n",
      "  7.54545455  7.63636364  7.72727273  7.81818182  7.90909091  8.\n",
      "  8.09090909  8.18181818  8.27272727  8.36363636  8.45454545  8.54545455\n",
      "  8.63636364  8.72727273  8.81818182  8.90909091  9.          9.09090909\n",
      "  9.18181818  9.27272727  9.36363636  9.45454545  9.54545455  9.63636364\n",
      "  9.72727273  9.81818182  9.90909091 10.        ];, score=nan total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 11/30] END classifier=BernoulliNB(), classifier__alpha=[ 1.          1.09090909  1.18181818  1.27272727  1.36363636  1.45454545\n",
      "  1.54545455  1.63636364  1.72727273  1.81818182  1.90909091  2.\n",
      "  2.09090909  2.18181818  2.27272727  2.36363636  2.45454545  2.54545455\n",
      "  2.63636364  2.72727273  2.81818182  2.90909091  3.          3.09090909\n",
      "  3.18181818  3.27272727  3.36363636  3.45454545  3.54545455  3.63636364\n",
      "  3.72727273  3.81818182  3.90909091  4.          4.09090909  4.18181818\n",
      "  4.27272727  4.36363636  4.45454545  4.54545455  4.63636364  4.72727273\n",
      "  4.81818182  4.90909091  5.          5.09090909  5.18181818  5.27272727\n",
      "  5.36363636  5.45454545  5.54545455  5.63636364  5.72727273  5.81818182\n",
      "  5.90909091  6.          6.09090909  6.18181818  6.27272727  6.36363636\n",
      "  6.45454545  6.54545455  6.63636364  6.72727273  6.81818182  6.90909091\n",
      "  7.          7.09090909  7.18181818  7.27272727  7.36363636  7.45454545\n",
      "  7.54545455  7.63636364  7.72727273  7.81818182  7.90909091  8.\n",
      "  8.09090909  8.18181818  8.27272727  8.36363636  8.45454545  8.54545455\n",
      "  8.63636364  8.72727273  8.81818182  8.90909091  9.          9.09090909\n",
      "  9.18181818  9.27272727  9.36363636  9.45454545  9.54545455  9.63636364\n",
      "  9.72727273  9.81818182  9.90909091 10.        ];, score=nan total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 12/30] END classifier=BernoulliNB(), classifier__alpha=[ 1.          1.09090909  1.18181818  1.27272727  1.36363636  1.45454545\n",
      "  1.54545455  1.63636364  1.72727273  1.81818182  1.90909091  2.\n",
      "  2.09090909  2.18181818  2.27272727  2.36363636  2.45454545  2.54545455\n",
      "  2.63636364  2.72727273  2.81818182  2.90909091  3.          3.09090909\n",
      "  3.18181818  3.27272727  3.36363636  3.45454545  3.54545455  3.63636364\n",
      "  3.72727273  3.81818182  3.90909091  4.          4.09090909  4.18181818\n",
      "  4.27272727  4.36363636  4.45454545  4.54545455  4.63636364  4.72727273\n",
      "  4.81818182  4.90909091  5.          5.09090909  5.18181818  5.27272727\n",
      "  5.36363636  5.45454545  5.54545455  5.63636364  5.72727273  5.81818182\n",
      "  5.90909091  6.          6.09090909  6.18181818  6.27272727  6.36363636\n",
      "  6.45454545  6.54545455  6.63636364  6.72727273  6.81818182  6.90909091\n",
      "  7.          7.09090909  7.18181818  7.27272727  7.36363636  7.45454545\n",
      "  7.54545455  7.63636364  7.72727273  7.81818182  7.90909091  8.\n",
      "  8.09090909  8.18181818  8.27272727  8.36363636  8.45454545  8.54545455\n",
      "  8.63636364  8.72727273  8.81818182  8.90909091  9.          9.09090909\n",
      "  9.18181818  9.27272727  9.36363636  9.45454545  9.54545455  9.63636364\n",
      "  9.72727273  9.81818182  9.90909091 10.        ];, score=nan total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 13/30] END classifier=BernoulliNB(), classifier__alpha=[ 1.          1.09090909  1.18181818  1.27272727  1.36363636  1.45454545\n",
      "  1.54545455  1.63636364  1.72727273  1.81818182  1.90909091  2.\n",
      "  2.09090909  2.18181818  2.27272727  2.36363636  2.45454545  2.54545455\n",
      "  2.63636364  2.72727273  2.81818182  2.90909091  3.          3.09090909\n",
      "  3.18181818  3.27272727  3.36363636  3.45454545  3.54545455  3.63636364\n",
      "  3.72727273  3.81818182  3.90909091  4.          4.09090909  4.18181818\n",
      "  4.27272727  4.36363636  4.45454545  4.54545455  4.63636364  4.72727273\n",
      "  4.81818182  4.90909091  5.          5.09090909  5.18181818  5.27272727\n",
      "  5.36363636  5.45454545  5.54545455  5.63636364  5.72727273  5.81818182\n",
      "  5.90909091  6.          6.09090909  6.18181818  6.27272727  6.36363636\n",
      "  6.45454545  6.54545455  6.63636364  6.72727273  6.81818182  6.90909091\n",
      "  7.          7.09090909  7.18181818  7.27272727  7.36363636  7.45454545\n",
      "  7.54545455  7.63636364  7.72727273  7.81818182  7.90909091  8.\n",
      "  8.09090909  8.18181818  8.27272727  8.36363636  8.45454545  8.54545455\n",
      "  8.63636364  8.72727273  8.81818182  8.90909091  9.          9.09090909\n",
      "  9.18181818  9.27272727  9.36363636  9.45454545  9.54545455  9.63636364\n",
      "  9.72727273  9.81818182  9.90909091 10.        ];, score=nan total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 14/30] END classifier=BernoulliNB(), classifier__alpha=[ 1.          1.09090909  1.18181818  1.27272727  1.36363636  1.45454545\n",
      "  1.54545455  1.63636364  1.72727273  1.81818182  1.90909091  2.\n",
      "  2.09090909  2.18181818  2.27272727  2.36363636  2.45454545  2.54545455\n",
      "  2.63636364  2.72727273  2.81818182  2.90909091  3.          3.09090909\n",
      "  3.18181818  3.27272727  3.36363636  3.45454545  3.54545455  3.63636364\n",
      "  3.72727273  3.81818182  3.90909091  4.          4.09090909  4.18181818\n",
      "  4.27272727  4.36363636  4.45454545  4.54545455  4.63636364  4.72727273\n",
      "  4.81818182  4.90909091  5.          5.09090909  5.18181818  5.27272727\n",
      "  5.36363636  5.45454545  5.54545455  5.63636364  5.72727273  5.81818182\n",
      "  5.90909091  6.          6.09090909  6.18181818  6.27272727  6.36363636\n",
      "  6.45454545  6.54545455  6.63636364  6.72727273  6.81818182  6.90909091\n",
      "  7.          7.09090909  7.18181818  7.27272727  7.36363636  7.45454545\n",
      "  7.54545455  7.63636364  7.72727273  7.81818182  7.90909091  8.\n",
      "  8.09090909  8.18181818  8.27272727  8.36363636  8.45454545  8.54545455\n",
      "  8.63636364  8.72727273  8.81818182  8.90909091  9.          9.09090909\n",
      "  9.18181818  9.27272727  9.36363636  9.45454545  9.54545455  9.63636364\n",
      "  9.72727273  9.81818182  9.90909091 10.        ];, score=nan total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 15/30] END classifier=BernoulliNB(), classifier__alpha=[ 1.          1.09090909  1.18181818  1.27272727  1.36363636  1.45454545\n",
      "  1.54545455  1.63636364  1.72727273  1.81818182  1.90909091  2.\n",
      "  2.09090909  2.18181818  2.27272727  2.36363636  2.45454545  2.54545455\n",
      "  2.63636364  2.72727273  2.81818182  2.90909091  3.          3.09090909\n",
      "  3.18181818  3.27272727  3.36363636  3.45454545  3.54545455  3.63636364\n",
      "  3.72727273  3.81818182  3.90909091  4.          4.09090909  4.18181818\n",
      "  4.27272727  4.36363636  4.45454545  4.54545455  4.63636364  4.72727273\n",
      "  4.81818182  4.90909091  5.          5.09090909  5.18181818  5.27272727\n",
      "  5.36363636  5.45454545  5.54545455  5.63636364  5.72727273  5.81818182\n",
      "  5.90909091  6.          6.09090909  6.18181818  6.27272727  6.36363636\n",
      "  6.45454545  6.54545455  6.63636364  6.72727273  6.81818182  6.90909091\n",
      "  7.          7.09090909  7.18181818  7.27272727  7.36363636  7.45454545\n",
      "  7.54545455  7.63636364  7.72727273  7.81818182  7.90909091  8.\n",
      "  8.09090909  8.18181818  8.27272727  8.36363636  8.45454545  8.54545455\n",
      "  8.63636364  8.72727273  8.81818182  8.90909091  9.          9.09090909\n",
      "  9.18181818  9.27272727  9.36363636  9.45454545  9.54545455  9.63636364\n",
      "  9.72727273  9.81818182  9.90909091 10.        ];, score=nan total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 16/30] END classifier=BernoulliNB(), classifier__alpha=[ 1.          1.09090909  1.18181818  1.27272727  1.36363636  1.45454545\n",
      "  1.54545455  1.63636364  1.72727273  1.81818182  1.90909091  2.\n",
      "  2.09090909  2.18181818  2.27272727  2.36363636  2.45454545  2.54545455\n",
      "  2.63636364  2.72727273  2.81818182  2.90909091  3.          3.09090909\n",
      "  3.18181818  3.27272727  3.36363636  3.45454545  3.54545455  3.63636364\n",
      "  3.72727273  3.81818182  3.90909091  4.          4.09090909  4.18181818\n",
      "  4.27272727  4.36363636  4.45454545  4.54545455  4.63636364  4.72727273\n",
      "  4.81818182  4.90909091  5.          5.09090909  5.18181818  5.27272727\n",
      "  5.36363636  5.45454545  5.54545455  5.63636364  5.72727273  5.81818182\n",
      "  5.90909091  6.          6.09090909  6.18181818  6.27272727  6.36363636\n",
      "  6.45454545  6.54545455  6.63636364  6.72727273  6.81818182  6.90909091\n",
      "  7.          7.09090909  7.18181818  7.27272727  7.36363636  7.45454545\n",
      "  7.54545455  7.63636364  7.72727273  7.81818182  7.90909091  8.\n",
      "  8.09090909  8.18181818  8.27272727  8.36363636  8.45454545  8.54545455\n",
      "  8.63636364  8.72727273  8.81818182  8.90909091  9.          9.09090909\n",
      "  9.18181818  9.27272727  9.36363636  9.45454545  9.54545455  9.63636364\n",
      "  9.72727273  9.81818182  9.90909091 10.        ];, score=nan total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 17/30] END classifier=BernoulliNB(), classifier__alpha=[ 1.          1.09090909  1.18181818  1.27272727  1.36363636  1.45454545\n",
      "  1.54545455  1.63636364  1.72727273  1.81818182  1.90909091  2.\n",
      "  2.09090909  2.18181818  2.27272727  2.36363636  2.45454545  2.54545455\n",
      "  2.63636364  2.72727273  2.81818182  2.90909091  3.          3.09090909\n",
      "  3.18181818  3.27272727  3.36363636  3.45454545  3.54545455  3.63636364\n",
      "  3.72727273  3.81818182  3.90909091  4.          4.09090909  4.18181818\n",
      "  4.27272727  4.36363636  4.45454545  4.54545455  4.63636364  4.72727273\n",
      "  4.81818182  4.90909091  5.          5.09090909  5.18181818  5.27272727\n",
      "  5.36363636  5.45454545  5.54545455  5.63636364  5.72727273  5.81818182\n",
      "  5.90909091  6.          6.09090909  6.18181818  6.27272727  6.36363636\n",
      "  6.45454545  6.54545455  6.63636364  6.72727273  6.81818182  6.90909091\n",
      "  7.          7.09090909  7.18181818  7.27272727  7.36363636  7.45454545\n",
      "  7.54545455  7.63636364  7.72727273  7.81818182  7.90909091  8.\n",
      "  8.09090909  8.18181818  8.27272727  8.36363636  8.45454545  8.54545455\n",
      "  8.63636364  8.72727273  8.81818182  8.90909091  9.          9.09090909\n",
      "  9.18181818  9.27272727  9.36363636  9.45454545  9.54545455  9.63636364\n",
      "  9.72727273  9.81818182  9.90909091 10.        ];, score=nan total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 18/30] END classifier=BernoulliNB(), classifier__alpha=[ 1.          1.09090909  1.18181818  1.27272727  1.36363636  1.45454545\n",
      "  1.54545455  1.63636364  1.72727273  1.81818182  1.90909091  2.\n",
      "  2.09090909  2.18181818  2.27272727  2.36363636  2.45454545  2.54545455\n",
      "  2.63636364  2.72727273  2.81818182  2.90909091  3.          3.09090909\n",
      "  3.18181818  3.27272727  3.36363636  3.45454545  3.54545455  3.63636364\n",
      "  3.72727273  3.81818182  3.90909091  4.          4.09090909  4.18181818\n",
      "  4.27272727  4.36363636  4.45454545  4.54545455  4.63636364  4.72727273\n",
      "  4.81818182  4.90909091  5.          5.09090909  5.18181818  5.27272727\n",
      "  5.36363636  5.45454545  5.54545455  5.63636364  5.72727273  5.81818182\n",
      "  5.90909091  6.          6.09090909  6.18181818  6.27272727  6.36363636\n",
      "  6.45454545  6.54545455  6.63636364  6.72727273  6.81818182  6.90909091\n",
      "  7.          7.09090909  7.18181818  7.27272727  7.36363636  7.45454545\n",
      "  7.54545455  7.63636364  7.72727273  7.81818182  7.90909091  8.\n",
      "  8.09090909  8.18181818  8.27272727  8.36363636  8.45454545  8.54545455\n",
      "  8.63636364  8.72727273  8.81818182  8.90909091  9.          9.09090909\n",
      "  9.18181818  9.27272727  9.36363636  9.45454545  9.54545455  9.63636364\n",
      "  9.72727273  9.81818182  9.90909091 10.        ];, score=nan total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 19/30] END classifier=BernoulliNB(), classifier__alpha=[ 1.          1.09090909  1.18181818  1.27272727  1.36363636  1.45454545\n",
      "  1.54545455  1.63636364  1.72727273  1.81818182  1.90909091  2.\n",
      "  2.09090909  2.18181818  2.27272727  2.36363636  2.45454545  2.54545455\n",
      "  2.63636364  2.72727273  2.81818182  2.90909091  3.          3.09090909\n",
      "  3.18181818  3.27272727  3.36363636  3.45454545  3.54545455  3.63636364\n",
      "  3.72727273  3.81818182  3.90909091  4.          4.09090909  4.18181818\n",
      "  4.27272727  4.36363636  4.45454545  4.54545455  4.63636364  4.72727273\n",
      "  4.81818182  4.90909091  5.          5.09090909  5.18181818  5.27272727\n",
      "  5.36363636  5.45454545  5.54545455  5.63636364  5.72727273  5.81818182\n",
      "  5.90909091  6.          6.09090909  6.18181818  6.27272727  6.36363636\n",
      "  6.45454545  6.54545455  6.63636364  6.72727273  6.81818182  6.90909091\n",
      "  7.          7.09090909  7.18181818  7.27272727  7.36363636  7.45454545\n",
      "  7.54545455  7.63636364  7.72727273  7.81818182  7.90909091  8.\n",
      "  8.09090909  8.18181818  8.27272727  8.36363636  8.45454545  8.54545455\n",
      "  8.63636364  8.72727273  8.81818182  8.90909091  9.          9.09090909\n",
      "  9.18181818  9.27272727  9.36363636  9.45454545  9.54545455  9.63636364\n",
      "  9.72727273  9.81818182  9.90909091 10.        ];, score=nan total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 20/30] END classifier=BernoulliNB(), classifier__alpha=[ 1.          1.09090909  1.18181818  1.27272727  1.36363636  1.45454545\n",
      "  1.54545455  1.63636364  1.72727273  1.81818182  1.90909091  2.\n",
      "  2.09090909  2.18181818  2.27272727  2.36363636  2.45454545  2.54545455\n",
      "  2.63636364  2.72727273  2.81818182  2.90909091  3.          3.09090909\n",
      "  3.18181818  3.27272727  3.36363636  3.45454545  3.54545455  3.63636364\n",
      "  3.72727273  3.81818182  3.90909091  4.          4.09090909  4.18181818\n",
      "  4.27272727  4.36363636  4.45454545  4.54545455  4.63636364  4.72727273\n",
      "  4.81818182  4.90909091  5.          5.09090909  5.18181818  5.27272727\n",
      "  5.36363636  5.45454545  5.54545455  5.63636364  5.72727273  5.81818182\n",
      "  5.90909091  6.          6.09090909  6.18181818  6.27272727  6.36363636\n",
      "  6.45454545  6.54545455  6.63636364  6.72727273  6.81818182  6.90909091\n",
      "  7.          7.09090909  7.18181818  7.27272727  7.36363636  7.45454545\n",
      "  7.54545455  7.63636364  7.72727273  7.81818182  7.90909091  8.\n",
      "  8.09090909  8.18181818  8.27272727  8.36363636  8.45454545  8.54545455\n",
      "  8.63636364  8.72727273  8.81818182  8.90909091  9.          9.09090909\n",
      "  9.18181818  9.27272727  9.36363636  9.45454545  9.54545455  9.63636364\n",
      "  9.72727273  9.81818182  9.90909091 10.        ];, score=nan total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 21/30] END classifier=BernoulliNB(), classifier__alpha=[ 1.          1.09090909  1.18181818  1.27272727  1.36363636  1.45454545\n",
      "  1.54545455  1.63636364  1.72727273  1.81818182  1.90909091  2.\n",
      "  2.09090909  2.18181818  2.27272727  2.36363636  2.45454545  2.54545455\n",
      "  2.63636364  2.72727273  2.81818182  2.90909091  3.          3.09090909\n",
      "  3.18181818  3.27272727  3.36363636  3.45454545  3.54545455  3.63636364\n",
      "  3.72727273  3.81818182  3.90909091  4.          4.09090909  4.18181818\n",
      "  4.27272727  4.36363636  4.45454545  4.54545455  4.63636364  4.72727273\n",
      "  4.81818182  4.90909091  5.          5.09090909  5.18181818  5.27272727\n",
      "  5.36363636  5.45454545  5.54545455  5.63636364  5.72727273  5.81818182\n",
      "  5.90909091  6.          6.09090909  6.18181818  6.27272727  6.36363636\n",
      "  6.45454545  6.54545455  6.63636364  6.72727273  6.81818182  6.90909091\n",
      "  7.          7.09090909  7.18181818  7.27272727  7.36363636  7.45454545\n",
      "  7.54545455  7.63636364  7.72727273  7.81818182  7.90909091  8.\n",
      "  8.09090909  8.18181818  8.27272727  8.36363636  8.45454545  8.54545455\n",
      "  8.63636364  8.72727273  8.81818182  8.90909091  9.          9.09090909\n",
      "  9.18181818  9.27272727  9.36363636  9.45454545  9.54545455  9.63636364\n",
      "  9.72727273  9.81818182  9.90909091 10.        ];, score=nan total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 22/30] END classifier=BernoulliNB(), classifier__alpha=[ 1.          1.09090909  1.18181818  1.27272727  1.36363636  1.45454545\n",
      "  1.54545455  1.63636364  1.72727273  1.81818182  1.90909091  2.\n",
      "  2.09090909  2.18181818  2.27272727  2.36363636  2.45454545  2.54545455\n",
      "  2.63636364  2.72727273  2.81818182  2.90909091  3.          3.09090909\n",
      "  3.18181818  3.27272727  3.36363636  3.45454545  3.54545455  3.63636364\n",
      "  3.72727273  3.81818182  3.90909091  4.          4.09090909  4.18181818\n",
      "  4.27272727  4.36363636  4.45454545  4.54545455  4.63636364  4.72727273\n",
      "  4.81818182  4.90909091  5.          5.09090909  5.18181818  5.27272727\n",
      "  5.36363636  5.45454545  5.54545455  5.63636364  5.72727273  5.81818182\n",
      "  5.90909091  6.          6.09090909  6.18181818  6.27272727  6.36363636\n",
      "  6.45454545  6.54545455  6.63636364  6.72727273  6.81818182  6.90909091\n",
      "  7.          7.09090909  7.18181818  7.27272727  7.36363636  7.45454545\n",
      "  7.54545455  7.63636364  7.72727273  7.81818182  7.90909091  8.\n",
      "  8.09090909  8.18181818  8.27272727  8.36363636  8.45454545  8.54545455\n",
      "  8.63636364  8.72727273  8.81818182  8.90909091  9.          9.09090909\n",
      "  9.18181818  9.27272727  9.36363636  9.45454545  9.54545455  9.63636364\n",
      "  9.72727273  9.81818182  9.90909091 10.        ];, score=nan total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 23/30] END classifier=BernoulliNB(), classifier__alpha=[ 1.          1.09090909  1.18181818  1.27272727  1.36363636  1.45454545\n",
      "  1.54545455  1.63636364  1.72727273  1.81818182  1.90909091  2.\n",
      "  2.09090909  2.18181818  2.27272727  2.36363636  2.45454545  2.54545455\n",
      "  2.63636364  2.72727273  2.81818182  2.90909091  3.          3.09090909\n",
      "  3.18181818  3.27272727  3.36363636  3.45454545  3.54545455  3.63636364\n",
      "  3.72727273  3.81818182  3.90909091  4.          4.09090909  4.18181818\n",
      "  4.27272727  4.36363636  4.45454545  4.54545455  4.63636364  4.72727273\n",
      "  4.81818182  4.90909091  5.          5.09090909  5.18181818  5.27272727\n",
      "  5.36363636  5.45454545  5.54545455  5.63636364  5.72727273  5.81818182\n",
      "  5.90909091  6.          6.09090909  6.18181818  6.27272727  6.36363636\n",
      "  6.45454545  6.54545455  6.63636364  6.72727273  6.81818182  6.90909091\n",
      "  7.          7.09090909  7.18181818  7.27272727  7.36363636  7.45454545\n",
      "  7.54545455  7.63636364  7.72727273  7.81818182  7.90909091  8.\n",
      "  8.09090909  8.18181818  8.27272727  8.36363636  8.45454545  8.54545455\n",
      "  8.63636364  8.72727273  8.81818182  8.90909091  9.          9.09090909\n",
      "  9.18181818  9.27272727  9.36363636  9.45454545  9.54545455  9.63636364\n",
      "  9.72727273  9.81818182  9.90909091 10.        ];, score=nan total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 24/30] END classifier=BernoulliNB(), classifier__alpha=[ 1.          1.09090909  1.18181818  1.27272727  1.36363636  1.45454545\n",
      "  1.54545455  1.63636364  1.72727273  1.81818182  1.90909091  2.\n",
      "  2.09090909  2.18181818  2.27272727  2.36363636  2.45454545  2.54545455\n",
      "  2.63636364  2.72727273  2.81818182  2.90909091  3.          3.09090909\n",
      "  3.18181818  3.27272727  3.36363636  3.45454545  3.54545455  3.63636364\n",
      "  3.72727273  3.81818182  3.90909091  4.          4.09090909  4.18181818\n",
      "  4.27272727  4.36363636  4.45454545  4.54545455  4.63636364  4.72727273\n",
      "  4.81818182  4.90909091  5.          5.09090909  5.18181818  5.27272727\n",
      "  5.36363636  5.45454545  5.54545455  5.63636364  5.72727273  5.81818182\n",
      "  5.90909091  6.          6.09090909  6.18181818  6.27272727  6.36363636\n",
      "  6.45454545  6.54545455  6.63636364  6.72727273  6.81818182  6.90909091\n",
      "  7.          7.09090909  7.18181818  7.27272727  7.36363636  7.45454545\n",
      "  7.54545455  7.63636364  7.72727273  7.81818182  7.90909091  8.\n",
      "  8.09090909  8.18181818  8.27272727  8.36363636  8.45454545  8.54545455\n",
      "  8.63636364  8.72727273  8.81818182  8.90909091  9.          9.09090909\n",
      "  9.18181818  9.27272727  9.36363636  9.45454545  9.54545455  9.63636364\n",
      "  9.72727273  9.81818182  9.90909091 10.        ];, score=nan total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 25/30] END classifier=BernoulliNB(), classifier__alpha=[ 1.          1.09090909  1.18181818  1.27272727  1.36363636  1.45454545\n",
      "  1.54545455  1.63636364  1.72727273  1.81818182  1.90909091  2.\n",
      "  2.09090909  2.18181818  2.27272727  2.36363636  2.45454545  2.54545455\n",
      "  2.63636364  2.72727273  2.81818182  2.90909091  3.          3.09090909\n",
      "  3.18181818  3.27272727  3.36363636  3.45454545  3.54545455  3.63636364\n",
      "  3.72727273  3.81818182  3.90909091  4.          4.09090909  4.18181818\n",
      "  4.27272727  4.36363636  4.45454545  4.54545455  4.63636364  4.72727273\n",
      "  4.81818182  4.90909091  5.          5.09090909  5.18181818  5.27272727\n",
      "  5.36363636  5.45454545  5.54545455  5.63636364  5.72727273  5.81818182\n",
      "  5.90909091  6.          6.09090909  6.18181818  6.27272727  6.36363636\n",
      "  6.45454545  6.54545455  6.63636364  6.72727273  6.81818182  6.90909091\n",
      "  7.          7.09090909  7.18181818  7.27272727  7.36363636  7.45454545\n",
      "  7.54545455  7.63636364  7.72727273  7.81818182  7.90909091  8.\n",
      "  8.09090909  8.18181818  8.27272727  8.36363636  8.45454545  8.54545455\n",
      "  8.63636364  8.72727273  8.81818182  8.90909091  9.          9.09090909\n",
      "  9.18181818  9.27272727  9.36363636  9.45454545  9.54545455  9.63636364\n",
      "  9.72727273  9.81818182  9.90909091 10.        ];, score=nan total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 26/30] END classifier=BernoulliNB(), classifier__alpha=[ 1.          1.09090909  1.18181818  1.27272727  1.36363636  1.45454545\n",
      "  1.54545455  1.63636364  1.72727273  1.81818182  1.90909091  2.\n",
      "  2.09090909  2.18181818  2.27272727  2.36363636  2.45454545  2.54545455\n",
      "  2.63636364  2.72727273  2.81818182  2.90909091  3.          3.09090909\n",
      "  3.18181818  3.27272727  3.36363636  3.45454545  3.54545455  3.63636364\n",
      "  3.72727273  3.81818182  3.90909091  4.          4.09090909  4.18181818\n",
      "  4.27272727  4.36363636  4.45454545  4.54545455  4.63636364  4.72727273\n",
      "  4.81818182  4.90909091  5.          5.09090909  5.18181818  5.27272727\n",
      "  5.36363636  5.45454545  5.54545455  5.63636364  5.72727273  5.81818182\n",
      "  5.90909091  6.          6.09090909  6.18181818  6.27272727  6.36363636\n",
      "  6.45454545  6.54545455  6.63636364  6.72727273  6.81818182  6.90909091\n",
      "  7.          7.09090909  7.18181818  7.27272727  7.36363636  7.45454545\n",
      "  7.54545455  7.63636364  7.72727273  7.81818182  7.90909091  8.\n",
      "  8.09090909  8.18181818  8.27272727  8.36363636  8.45454545  8.54545455\n",
      "  8.63636364  8.72727273  8.81818182  8.90909091  9.          9.09090909\n",
      "  9.18181818  9.27272727  9.36363636  9.45454545  9.54545455  9.63636364\n",
      "  9.72727273  9.81818182  9.90909091 10.        ];, score=nan total time=   0.1s\n",
      "[CV 27/30] END classifier=BernoulliNB(), classifier__alpha=[ 1.          1.09090909  1.18181818  1.27272727  1.36363636  1.45454545\n",
      "  1.54545455  1.63636364  1.72727273  1.81818182  1.90909091  2.\n",
      "  2.09090909  2.18181818  2.27272727  2.36363636  2.45454545  2.54545455\n",
      "  2.63636364  2.72727273  2.81818182  2.90909091  3.          3.09090909\n",
      "  3.18181818  3.27272727  3.36363636  3.45454545  3.54545455  3.63636364\n",
      "  3.72727273  3.81818182  3.90909091  4.          4.09090909  4.18181818\n",
      "  4.27272727  4.36363636  4.45454545  4.54545455  4.63636364  4.72727273\n",
      "  4.81818182  4.90909091  5.          5.09090909  5.18181818  5.27272727\n",
      "  5.36363636  5.45454545  5.54545455  5.63636364  5.72727273  5.81818182\n",
      "  5.90909091  6.          6.09090909  6.18181818  6.27272727  6.36363636\n",
      "  6.45454545  6.54545455  6.63636364  6.72727273  6.81818182  6.90909091\n",
      "  7.          7.09090909  7.18181818  7.27272727  7.36363636  7.45454545\n",
      "  7.54545455  7.63636364  7.72727273  7.81818182  7.90909091  8.\n",
      "  8.09090909  8.18181818  8.27272727  8.36363636  8.45454545  8.54545455\n",
      "  8.63636364  8.72727273  8.81818182  8.90909091  9.          9.09090909\n",
      "  9.18181818  9.27272727  9.36363636  9.45454545  9.54545455  9.63636364\n",
      "  9.72727273  9.81818182  9.90909091 10.        ];, score=nan total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 28/30] END classifier=BernoulliNB(), classifier__alpha=[ 1.          1.09090909  1.18181818  1.27272727  1.36363636  1.45454545\n",
      "  1.54545455  1.63636364  1.72727273  1.81818182  1.90909091  2.\n",
      "  2.09090909  2.18181818  2.27272727  2.36363636  2.45454545  2.54545455\n",
      "  2.63636364  2.72727273  2.81818182  2.90909091  3.          3.09090909\n",
      "  3.18181818  3.27272727  3.36363636  3.45454545  3.54545455  3.63636364\n",
      "  3.72727273  3.81818182  3.90909091  4.          4.09090909  4.18181818\n",
      "  4.27272727  4.36363636  4.45454545  4.54545455  4.63636364  4.72727273\n",
      "  4.81818182  4.90909091  5.          5.09090909  5.18181818  5.27272727\n",
      "  5.36363636  5.45454545  5.54545455  5.63636364  5.72727273  5.81818182\n",
      "  5.90909091  6.          6.09090909  6.18181818  6.27272727  6.36363636\n",
      "  6.45454545  6.54545455  6.63636364  6.72727273  6.81818182  6.90909091\n",
      "  7.          7.09090909  7.18181818  7.27272727  7.36363636  7.45454545\n",
      "  7.54545455  7.63636364  7.72727273  7.81818182  7.90909091  8.\n",
      "  8.09090909  8.18181818  8.27272727  8.36363636  8.45454545  8.54545455\n",
      "  8.63636364  8.72727273  8.81818182  8.90909091  9.          9.09090909\n",
      "  9.18181818  9.27272727  9.36363636  9.45454545  9.54545455  9.63636364\n",
      "  9.72727273  9.81818182  9.90909091 10.        ];, score=nan total time=   0.1s\n",
      "[CV 29/30] END classifier=BernoulliNB(), classifier__alpha=[ 1.          1.09090909  1.18181818  1.27272727  1.36363636  1.45454545\n",
      "  1.54545455  1.63636364  1.72727273  1.81818182  1.90909091  2.\n",
      "  2.09090909  2.18181818  2.27272727  2.36363636  2.45454545  2.54545455\n",
      "  2.63636364  2.72727273  2.81818182  2.90909091  3.          3.09090909\n",
      "  3.18181818  3.27272727  3.36363636  3.45454545  3.54545455  3.63636364\n",
      "  3.72727273  3.81818182  3.90909091  4.          4.09090909  4.18181818\n",
      "  4.27272727  4.36363636  4.45454545  4.54545455  4.63636364  4.72727273\n",
      "  4.81818182  4.90909091  5.          5.09090909  5.18181818  5.27272727\n",
      "  5.36363636  5.45454545  5.54545455  5.63636364  5.72727273  5.81818182\n",
      "  5.90909091  6.          6.09090909  6.18181818  6.27272727  6.36363636\n",
      "  6.45454545  6.54545455  6.63636364  6.72727273  6.81818182  6.90909091\n",
      "  7.          7.09090909  7.18181818  7.27272727  7.36363636  7.45454545\n",
      "  7.54545455  7.63636364  7.72727273  7.81818182  7.90909091  8.\n",
      "  8.09090909  8.18181818  8.27272727  8.36363636  8.45454545  8.54545455\n",
      "  8.63636364  8.72727273  8.81818182  8.90909091  9.          9.09090909\n",
      "  9.18181818  9.27272727  9.36363636  9.45454545  9.54545455  9.63636364\n",
      "  9.72727273  9.81818182  9.90909091 10.        ];, score=nan total time=   0.1s\n",
      "[CV 30/30] END classifier=BernoulliNB(), classifier__alpha=[ 1.          1.09090909  1.18181818  1.27272727  1.36363636  1.45454545\n",
      "  1.54545455  1.63636364  1.72727273  1.81818182  1.90909091  2.\n",
      "  2.09090909  2.18181818  2.27272727  2.36363636  2.45454545  2.54545455\n",
      "  2.63636364  2.72727273  2.81818182  2.90909091  3.          3.09090909\n",
      "  3.18181818  3.27272727  3.36363636  3.45454545  3.54545455  3.63636364\n",
      "  3.72727273  3.81818182  3.90909091  4.          4.09090909  4.18181818\n",
      "  4.27272727  4.36363636  4.45454545  4.54545455  4.63636364  4.72727273\n",
      "  4.81818182  4.90909091  5.          5.09090909  5.18181818  5.27272727\n",
      "  5.36363636  5.45454545  5.54545455  5.63636364  5.72727273  5.81818182\n",
      "  5.90909091  6.          6.09090909  6.18181818  6.27272727  6.36363636\n",
      "  6.45454545  6.54545455  6.63636364  6.72727273  6.81818182  6.90909091\n",
      "  7.          7.09090909  7.18181818  7.27272727  7.36363636  7.45454545\n",
      "  7.54545455  7.63636364  7.72727273  7.81818182  7.90909091  8.\n",
      "  8.09090909  8.18181818  8.27272727  8.36363636  8.45454545  8.54545455\n",
      "  8.63636364  8.72727273  8.81818182  8.90909091  9.          9.09090909\n",
      "  9.18181818  9.27272727  9.36363636  9.45454545  9.54545455  9.63636364\n",
      "  9.72727273  9.81818182  9.90909091 10.        ];, score=nan total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=10;, score=0.500 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=10;, score=0.500 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=10;, score=0.500 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=10;, score=0.500 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=10;, score=0.500 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=10;, score=0.499 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=10;, score=0.499 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 8/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=10;, score=0.500 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=10;, score=0.500 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 10/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=10;, score=0.499 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 11/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=10;, score=0.500 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 12/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=10;, score=0.500 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 13/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=10;, score=0.499 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 14/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=10;, score=0.500 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 15/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=10;, score=0.500 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 16/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=10;, score=0.498 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 17/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=10;, score=0.500 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 18/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=10;, score=0.499 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 19/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=10;, score=0.500 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 20/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=10;, score=0.499 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 21/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=10;, score=0.500 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 22/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=10;, score=0.499 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 23/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=10;, score=0.503 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 24/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=10;, score=0.500 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 25/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=10;, score=0.499 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 26/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=10;, score=0.499 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 27/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=10;, score=0.504 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 28/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=10;, score=0.500 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 29/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=10;, score=0.500 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 30/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=10;, score=0.503 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=100;, score=0.500 total time=   6.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=100;, score=0.500 total time=   6.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=100;, score=0.500 total time=   6.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=100;, score=0.500 total time=   6.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=100;, score=0.500 total time=   6.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 6/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=100;, score=0.500 total time=   6.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=100;, score=0.500 total time=   7.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 8/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=100;, score=0.500 total time=   6.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=100;, score=0.500 total time=   6.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 10/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=100;, score=0.500 total time=   6.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 11/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=100;, score=0.500 total time=   6.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 12/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=100;, score=0.500 total time=   6.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 13/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=100;, score=0.500 total time=   6.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 14/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=100;, score=0.500 total time=   6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 15/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=100;, score=0.500 total time=   6.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 16/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=100;, score=0.500 total time=   6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 17/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=100;, score=0.500 total time=   6.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 18/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=100;, score=0.500 total time=   6.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 19/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=100;, score=0.500 total time=   6.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 20/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=100;, score=0.500 total time=   6.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 21/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=100;, score=0.500 total time=   6.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 22/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=100;, score=0.500 total time=   6.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 23/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=100;, score=0.500 total time=   6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 24/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=100;, score=0.500 total time=   6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 25/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=100;, score=0.500 total time=   6.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 26/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=100;, score=0.500 total time=   6.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 27/30] END classifier=RandomForestClassifier(), classifier__class_weight=balanced, classifier__criterion=gini, classifier__max_features=auto, classifier__n_estimators=100;, score=0.500 total time=   6.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Marta\\Desktop\\Studia\\CDV\\IV semestr 2022L\\Wykorzystanie Pythona w uczeniu maszynowym\\ml_project\\project\\ML_PROJECT_2022\\notebooks\\grid-search.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Marta/Desktop/Studia/CDV/IV%20semestr%202022L/Wykorzystanie%20Pythona%20w%20uczeniu%20maszynowym/ml_project/project/ML_PROJECT_2022/notebooks/grid-search.ipynb#ch0000010?line=0'>1</a>\u001b[0m result \u001b[39m=\u001b[39m search\u001b[39m.\u001b[39;49mfit(X_pca, y)\n",
      "File \u001b[1;32mc:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\model_selection\\_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    885\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    886\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    887\u001b[0m     )\n\u001b[0;32m    889\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 891\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    893\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    894\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    895\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1392\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1391\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1392\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\model_selection\\_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    831\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    832\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    833\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    834\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    835\u001b[0m         )\n\u001b[0;32m    836\u001b[0m     )\n\u001b[1;32m--> 838\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    839\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    840\u001b[0m         clone(base_estimator),\n\u001b[0;32m    841\u001b[0m         X,\n\u001b[0;32m    842\u001b[0m         y,\n\u001b[0;32m    843\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    844\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    845\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    846\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    847\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    848\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    849\u001b[0m     )\n\u001b[0;32m    850\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    851\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    852\u001b[0m     )\n\u001b[0;32m    853\u001b[0m )\n\u001b[0;32m    855\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    856\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    857\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    858\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    859\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    860\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\joblib\\parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1044\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1046\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1047\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1050\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    780\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\utils\\fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    215\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> 216\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    678\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    679\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 680\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    682\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    683\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    684\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\pipeline.py:394\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    392\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    393\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[1;32m--> 394\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator\u001b[39m.\u001b[39mfit(Xt, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_last_step)\n\u001b[0;32m    396\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:450\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    439\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[0;32m    440\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m    441\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    442\u001b[0m ]\n\u001b[0;32m    444\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    445\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    448\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 450\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m    451\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[0;32m    452\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    453\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m_joblib_parallel_args(prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    454\u001b[0m )(\n\u001b[0;32m    455\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    456\u001b[0m         t,\n\u001b[0;32m    457\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[0;32m    458\u001b[0m         X,\n\u001b[0;32m    459\u001b[0m         y,\n\u001b[0;32m    460\u001b[0m         sample_weight,\n\u001b[0;32m    461\u001b[0m         i,\n\u001b[0;32m    462\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[0;32m    463\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    464\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m    465\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[0;32m    466\u001b[0m     )\n\u001b[0;32m    467\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[0;32m    468\u001b[0m )\n\u001b[0;32m    470\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\joblib\\parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1044\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1046\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1047\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1050\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    780\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\utils\\fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    215\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> 216\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:185\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    183\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[1;32m--> 185\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    186\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\tree\\_classes.py:937\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    899\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\n\u001b[0;32m    900\u001b[0m     \u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, X_idx_sorted\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdeprecated\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    901\u001b[0m ):\n\u001b[0;32m    902\u001b[0m     \u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    903\u001b[0m \n\u001b[0;32m    904\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    934\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    935\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 937\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    938\u001b[0m         X,\n\u001b[0;32m    939\u001b[0m         y,\n\u001b[0;32m    940\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    941\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m    942\u001b[0m         X_idx_sorted\u001b[39m=\u001b[39;49mX_idx_sorted,\n\u001b[0;32m    943\u001b[0m     )\n\u001b[0;32m    944\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Marta\\anaconda3\\envs\\python_in_ml\\lib\\site-packages\\sklearn\\tree\\_classes.py:420\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    410\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    411\u001b[0m         splitter,\n\u001b[0;32m    412\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    417\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    418\u001b[0m     )\n\u001b[1;32m--> 420\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[0;32m    422\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[0;32m    423\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "result = search.fit(X_pca, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('python_in_ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2e3cc47668b018802626e3a416c19566715ed21c2b0a730c77eabf314b853671"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
