{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_PROJECT_2022_DIM_RED.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMhMamBZVTMRiHnpmbGmC07",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MLBartkowiakChojnacki/ML_PROJECT_2022/blob/DIMENSIONALITY_REDUCTION/notebooks/ML_PROJECT_2022_DIM_RED.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#FEATURE SELECTION TRAINING"
      ],
      "metadata": {
        "id": "T6-ZSGXHTzD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ANOVA F-test Feature Selection\n",
        "The scikit-learn machine library provides an implementation of the ANOVA F-test in the function\n",
        "\n",
        "\n",
        "```\n",
        "f classif()\n",
        "```\n",
        "\n",
        " "
      ],
      "metadata": {
        "id": "xM_os8lrdnX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "Cj8cz7POT25b"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the dataset\n",
        "def load_dataset(filename):\n",
        "  # load the dataset\n",
        "  data = pd.read_csv(filename, header=None)\n",
        "  # retrieve array\n",
        "  dataset = data.values\n",
        "  # split into input and output variables\n",
        "  X = dataset[:, :-1]\n",
        "  y = dataset[:,-1]\n",
        "  return X, y\n",
        "\n",
        "X, y = load_dataset('https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv')"
      ],
      "metadata": {
        "id": "qnbyqPoHVk30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1tYuRyZUge9",
        "outputId": "08298310-e992-48e1-fe98-b8f116340235"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLMnDlAEUtJX",
        "outputId": "18bc842a-f0eb-42e7-a63b-ce641f9d01d9"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768,)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)"
      ],
      "metadata": {
        "id": "5UULjdKkVYmt"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example of anova f-test feature selection for numerical data\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "from matplotlib import pyplot\n",
        "# load the dataset\n",
        "def load_dataset(filename):\n",
        "  # load the dataset as a pandas DataFrame\n",
        "  data = read_csv(filename, header=None)\n",
        "  # retrieve numpy array\n",
        "  dataset = data.values\n",
        "  # split into input (X) and output (y) variables\n",
        "  X = dataset[:, :-1]\n",
        "  y = dataset[:,-1]\n",
        "  return X, y\n",
        "\n",
        "# feature selection\n",
        "def select_features(X_train, y_train, X_test):\n",
        "  # configure to select all features\n",
        "  fs = SelectKBest(score_func=f_classif, k='all')\n",
        "  # learn relationship from training data\n",
        "  fs.fit(X_train, y_train)\n",
        "  # transform train input data\n",
        "  X_train_fs = fs.transform(X_train)\n",
        "  # transform test input data\n",
        "  X_test_fs = fs.transform(X_test)\n",
        "  return X_train_fs, X_test_fs, fs\n",
        "# load the dataset\n",
        "X, y = load_dataset('https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv')\n",
        "# split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "# feature selection\n",
        "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)\n",
        "# what are scores for the features\n",
        "for i in range(len(fs.scores_)):\n",
        "  print('Feature %d: %f' % (i, fs.scores_[i]))\n",
        "# plot the scores\n",
        "pyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
        "pyplot.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "dhX1fPYXaWVN",
        "outputId": "0eea0a39-ec86-4030-b47e-a9925cadfb04"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature 0: 16.527385\n",
            "Feature 1: 131.325562\n",
            "Feature 2: 0.042371\n",
            "Feature 3: 1.415216\n",
            "Feature 4: 12.778966\n",
            "Feature 5: 49.209523\n",
            "Feature 6: 13.377142\n",
            "Feature 7: 25.126440\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Mutual Information Feature Selection\n",
        "The scikit-learn machine learning library provides\n",
        "an implementation of mutual information for feature selection with numeric input and categorical\n",
        "output variables via the function \n",
        "`mutual_info_classif()`\n",
        ". \n",
        "Like \n",
        "`f_classif()`\n",
        "it can be used\n",
        "in the SelectKBest feature selection strategy (and other strategies)."
      ],
      "metadata": {
        "id": "0OBOr3ladiR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# example of mutual information feature selection for numerical input data\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from matplotlib import pyplot\n",
        "# load the dataset\n",
        "def load_dataset(filename):\n",
        "# load the dataset as a pandas DataFrame\n",
        "  data = read_csv(filename, header=None)\n",
        "  # retrieve numpy array\n",
        "  dataset = data.values\n",
        "  # split into input (X) and output (y) variables\n",
        "  X = dataset[:, :-1]\n",
        "  y = dataset[:,-1]\n",
        "  return X, y\n",
        "# feature selection\n",
        "def select_features(X_train, y_train, X_test):\n",
        "  # configure to select all features\n",
        "  fs = SelectKBest(score_func=mutual_info_classif, k='all')\n",
        "  # learn relationship from training data\n",
        "  fs.fit(X_train, y_train)\n",
        "  # transform train input data\n",
        "  X_train_fs = fs.transform(X_train)\n",
        "  # transform test input data\n",
        "  X_test_fs = fs.transform(X_test)\n",
        "  return X_train_fs, X_test_fs, fs\n",
        "# load the dataset\n",
        "X, y = load_dataset('https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv')\n",
        "# split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "# feature selection\n",
        "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)\n",
        "# what are scores for the features\n",
        "for i in range(len(fs.scores_)):\n",
        "  print('Feature %d: %f' % (i, fs.scores_[i]))\n",
        "# plot the scores\n",
        "pyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
        "pyplot.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "c1aoITuReayy",
        "outputId": "836cd181-8e59-41cb-c639-5046ec6e786d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature 0: 0.024239\n",
            "Feature 1: 0.102582\n",
            "Feature 2: 0.030731\n",
            "Feature 3: 0.006934\n",
            "Feature 4: 0.053357\n",
            "Feature 5: 0.076066\n",
            "Feature 6: 0.017017\n",
            "Feature 7: 0.040614\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Modeling with selected features"
      ],
      "metadata": {
        "id": "Nje9bcI8f99h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model built using all features\n",
        "First we create base line with all features and then compare with model based\n",
        "on features selected with ANOVA and mutual information."
      ],
      "metadata": {
        "id": "SPaM_-DagA9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation of a model using all input features\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "# load the dataset\n",
        "def load_dataset(filename):\n",
        "  # load the dataset as a pandas DataFrame\n",
        "  data = read_csv(filename, header=None)\n",
        "  # retrieve numpy array\n",
        "  dataset = data.values\n",
        "  # split into input (X) and output (y) variables\n",
        "  X = dataset[:, :-1]\n",
        "  y = dataset[:,-1]\n",
        "  return X, y\n",
        "# load the dataset\n",
        "X, y = load_dataset('https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv')\n",
        "# split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "# fit the model\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "model.fit(X_train, y_train)\n",
        "# evaluate the model\n",
        "yhat = model.predict(X_test)\n",
        "# evaluate predictions\n",
        "accuracy = accuracy_score(y_test, yhat)\n",
        "print('Accuracy: %.2f' % (accuracy*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFWUenV7gEQs",
        "outputId": "03e161ee-1239-4ae3-ae8f-32cf9a8b34af"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 77.56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model Built Using ANOVA F-test Features"
      ],
      "metadata": {
        "id": "2XXNveMfhRHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation of a model using 4 features chosen with anova f-test\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "# load the dataset\n",
        "def load_dataset(filename):\n",
        "  # load the dataset as a pandas DataFrame\n",
        "  data = read_csv(filename, header=None)\n",
        "  # retrieve numpy array\n",
        "  dataset = data.values\n",
        "  # split into input (X) and output (y) variables\n",
        "  X = dataset[:, :-1]\n",
        "  y = dataset[:,-1]\n",
        "  return X, y\n",
        "\n",
        "# feature selection\n",
        "def select_features(X_train, y_train, X_test):\n",
        "  # configure to select a subset of features\n",
        "  fs = SelectKBest(score_func=f_classif, k=4)\n",
        "  # learn relationship from training data\n",
        "  fs.fit(X_train, y_train)\n",
        "  # transform train input data\n",
        "  X_train_fs = fs.transform(X_train)\n",
        "  # transform test input data\n",
        "  X_test_fs = fs.transform(X_test)\n",
        "  return X_train_fs, X_test_fs, fs\n",
        "# load the dataset\n",
        "X, y = load_dataset('https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv')\n",
        "# split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "# feature selection\n",
        "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)\n",
        "# fit the model\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "model.fit(X_train_fs, y_train)\n",
        "# evaluate the model\n",
        "yhat = model.predict(X_test_fs)\n",
        "# evaluate predictions\n",
        "accuracy = accuracy_score(y_test, yhat)\n",
        "print('Accuracy: %.2f' % (accuracy*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9E8fXTHqhSO9",
        "outputId": "5d36132d-dd55-4fcb-cb97-55fed1abccdb"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 78.74\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model Built Using Mutual Information Features"
      ],
      "metadata": {
        "id": "oZUXpPPbiHeZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation of a model using 4 features chosen with mutual information\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "# load the dataset\n",
        "def load_dataset(filename):\n",
        "  # load the dataset as a pandas DataFrame\n",
        "  data = read_csv(filename, header=None)\n",
        "  # retrieve numpy array\n",
        "  dataset = data.values\n",
        "  # split into input (X) and output (y) variables\n",
        "  X = dataset[:, :-1]\n",
        "  y = dataset[:,-1]\n",
        "  return X, y\n",
        "# feature selection\n",
        "def select_features(X_train, y_train, X_test):\n",
        "  # configure to select a subset of features\n",
        "  fs = SelectKBest(score_func=mutual_info_classif, k=4)\n",
        "  # learn relationship from training data\n",
        "  fs.fit(X_train, y_train)\n",
        "  # transform train input data\n",
        "  X_train_fs = fs.transform(X_train)\n",
        "  # transform test input data\n",
        "  X_test_fs = fs.transform(X_test)\n",
        "  return X_train_fs, X_test_fs, fs\n",
        "# load the dataset\n",
        "X, y = load_dataset('https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv')\n",
        "# split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "# feature selection\n",
        "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)\n",
        "# fit the model\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "model.fit(X_train_fs, y_train)\n",
        "# evaluate the model\n",
        "yhat = model.predict(X_test_fs)\n",
        "# evaluate predictions\n",
        "accuracy = accuracy_score(y_test, yhat)\n",
        "print('Accuracy: %.2f' % (accuracy*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaXKR85oiI-e",
        "outputId": "3756a2c8-2156-49e9-c90f-2cc01e71829a"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 77.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DIMENSIONALITY REDUCTION TRAINING\n",
        "https://machinelearningmastery.com/dimensionality-reduction-algorithms-with-python/\n",
        "\n"
      ],
      "metadata": {
        "id": "2F_SxRTH83mR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtV4uTHD8lre",
        "outputId": "d2f58991-521d-4716-d3f4-caea026cb192"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 20) (1000,)\n"
          ]
        }
      ],
      "source": [
        "# synthetic classification dataset\n",
        "from sklearn.datasets import make_classification\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, n_redundant=10, random_state=7)\n",
        "# summarize the dataset\n",
        "print(X.shape, y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcKaqghGCrNy",
        "outputId": "ce9caae8-6955-4cc4-a861-5172c26efed6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.08054814,  0.82273313, -1.21175254, ...,  2.88260938,\n",
              "         1.79160028, -4.29708787],\n",
              "       [-2.3302999 , -4.86608574, -3.88291317, ..., -0.14561581,\n",
              "        -0.55489384,  0.61420772],\n",
              "       [-1.19714954,  1.5556314 , -0.61871573, ...,  1.73481788,\n",
              "         0.13067403, -3.13351468],\n",
              "       ...,\n",
              "       [ 0.61415067, -3.04457734, -3.15540898, ..., -0.3321506 ,\n",
              "        -2.76644911,  0.81460546],\n",
              "       [ 3.34221924, -1.33613258, -0.34013763, ..., -3.95225071,\n",
              "         1.33439536, -0.69139029],\n",
              "       [-1.49207892,  2.75225738, -1.22655776, ..., -3.10146388,\n",
              "         2.34534351, -1.32021006]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9KrOLjRCwSd",
        "outputId": "05db1ebf-221a-4469-f1d8-a74c13d6e042"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
              "       1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "       0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1,\n",
              "       1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "       1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0,\n",
              "       1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
              "       1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
              "       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "       1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0,\n",
              "       1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0,\n",
              "       1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
              "       1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
              "       1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "       1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
              "       1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1,\n",
              "       0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1,\n",
              "       0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
              "       1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
              "       1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1,\n",
              "       1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0,\n",
              "       1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "       0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "       1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1,\n",
              "       0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1,\n",
              "       1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1,\n",
              "       1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
              "       0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0,\n",
              "       1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0,\n",
              "       1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0,\n",
              "       0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
              "       1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0,\n",
              "       0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "       0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n",
              "       0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
              "       1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
              "       0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
              "       0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0,\n",
              "       0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "       1, 0, 0, 1, 0, 0, 1, 1, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate logistic regression model on raw data\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, n_redundant=10, random_state=7)\n",
        "# define the model\n",
        "model = LogisticRegression()\n",
        "# evaluate model\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "# report performance\n",
        "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_B-29IqfDG_e",
        "outputId": "4939951f-06cf-4d4d-8370-fc5194893678"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.824 (0.034)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PCA"
      ],
      "metadata": {
        "id": "gW_LukgHEzEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate pca with logistic regression algorithm for classification\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, n_redundant=10, random_state=7)\n",
        "# define the pipeline\n",
        "steps = [('pca', PCA(n_components=10)), ('m', LogisticRegression())]\n",
        "model = Pipeline(steps=steps)\n",
        "# evaluate model\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "# report performance\n",
        "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wa55iPIQExx_",
        "outputId": "ec2160d6-9343-4d25-d751-3dfe0d55c3d2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.824 (0.034)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SVD"
      ],
      "metadata": {
        "id": "4zXHuinwH6BH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate svd with logistic regression algorithm for classification\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, n_redundant=10, random_state=7)\n",
        "# define the pipeline\n",
        "steps = [('svd', TruncatedSVD(n_components=10)), ('m', LogisticRegression())]\n",
        "model = Pipeline(steps=steps)\n",
        "# evaluate model\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "# report performance\n",
        "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UNEGa-YH9Mo",
        "outputId": "ad85e45f-4c9b-427e-bc91-188bdecb76d9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.824 (0.034)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LDA\n",
        "The number of dimensions for the projection is limited to 1 and C-1, where C is the number of classes. In this case, our dataset is a binary classification problem (two classes), limiting the number of dimensions to 1."
      ],
      "metadata": {
        "id": "9SGfIjcCIVSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate lda with logistic regression algorithm for classification\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, n_redundant=10, random_state=7)\n",
        "# define the pipeline\n",
        "steps = [('lda', LinearDiscriminantAnalysis(n_components=1)), ('m', LogisticRegression())]\n",
        "model = Pipeline(steps=steps)\n",
        "# evaluate model\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "# report performance\n",
        "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltrjsNTWIWqJ",
        "outputId": "eb6a939f-ad70-4202-ea10-c7886e57265c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.825 (0.034)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Isomap Embedding"
      ],
      "metadata": {
        "id": "pT9whxevJUxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate isomap with logistic regression algorithm for classification\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.manifold import Isomap\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, n_redundant=10, random_state=7)\n",
        "# define the pipeline\n",
        "steps = [('iso', Isomap(n_components=10)), ('m', LogisticRegression())]\n",
        "model = Pipeline(steps=steps)\n",
        "# evaluate model\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "# report performance\n",
        "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8x9v2ACgJWOu",
        "outputId": "1378ac5b-7c22-427e-8f5d-9b0edb829f3f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.888 (0.029)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Locally Linear Embedding"
      ],
      "metadata": {
        "id": "x24EtYAZL-yi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate lle and logistic regression for classification\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.manifold import LocallyLinearEmbedding\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, n_redundant=10, random_state=7)\n",
        "# define the pipeline\n",
        "steps = [('lle', LocallyLinearEmbedding(n_components=10)), ('m', LogisticRegression())]\n",
        "model = Pipeline(steps=steps)\n",
        "# evaluate model\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "# report performance\n",
        "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eK_IFvGeL_vJ",
        "outputId": "34a07703-bdfe-4c99-c913-9c5d61c7ba99"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.886 (0.028)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Modified Locally Linear Embedding"
      ],
      "metadata": {
        "id": "8J8xvKdWMteT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embedding that can be used as a dimensionality reduction data transform. The “method” argument must be set to ‘modified’ and the “n_components” argument can be set to configure the number of desired dimensions in the output of the transform which must be less than the “n_neighbors” argument."
      ],
      "metadata": {
        "id": "xIzo1VA8ObIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate modified lle and logistic regression for classification\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.manifold import LocallyLinearEmbedding\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, n_redundant=10, random_state=7)\n",
        "# define the pipeline\n",
        "steps = [('lle', LocallyLinearEmbedding(n_components=5, method='modified', n_neighbors=10)), ('m', LogisticRegression())]\n",
        "model = Pipeline(steps=steps)\n",
        "# evaluate model\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "# report performance\n",
        "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6cqi2NiMuvM",
        "outputId": "e14fe633-27fc-4a0a-b98f-c4e99353be64"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.848 (0.037)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DIMENSIONALITY REDUCTION AND HYPERPARAMETERS\n",
        "https://towardsdatascience.com/shap-for-feature-selection-and-hyperparameter-tuning-a330ec0ea104\n"
      ],
      "metadata": {
        "id": "tel_dSxDP42S"
      }
    }
  ]
}