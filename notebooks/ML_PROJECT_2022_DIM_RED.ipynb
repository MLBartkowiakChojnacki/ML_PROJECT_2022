{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_PROJECT_2022_DIM_RED.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNnT/efQL2DUy+/qLETrjy5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MLBartkowiakChojnacki/ML_PROJECT_2022/blob/DIMENSIONALITY_REDUCTION/notebooks/ML_PROJECT_2022_DIM_RED.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#FEATURE SELECTION TRAINING"
      ],
      "metadata": {
        "id": "T6-ZSGXHTzD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ANOVA F-test Feature Selection\n",
        "The scikit-learn machine library provides an implementation of the ANOVA F-test in the function\n",
        "\n",
        "\n",
        "```\n",
        "f classif()\n",
        "```\n",
        "\n",
        " "
      ],
      "metadata": {
        "id": "xM_os8lrdnX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "Cj8cz7POT25b"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the dataset\n",
        "def load_dataset(filename):\n",
        "  # load the dataset\n",
        "  data = pd.read_csv(filename, header=None)\n",
        "  # retrieve array\n",
        "  dataset = data.values\n",
        "  # split into input and output variables\n",
        "  X = dataset[:, :-1]\n",
        "  y = dataset[:,-1]\n",
        "  return X, y\n",
        "\n",
        "X, y = load_dataset('https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv')"
      ],
      "metadata": {
        "id": "qnbyqPoHVk30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1tYuRyZUge9",
        "outputId": "08298310-e992-48e1-fe98-b8f116340235"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLMnDlAEUtJX",
        "outputId": "18bc842a-f0eb-42e7-a63b-ce641f9d01d9"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768,)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)"
      ],
      "metadata": {
        "id": "5UULjdKkVYmt"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example of anova f-test feature selection for numerical data\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "from matplotlib import pyplot\n",
        "# load the dataset\n",
        "def load_dataset(filename):\n",
        "  # load the dataset as a pandas DataFrame\n",
        "  data = read_csv(filename, header=None)\n",
        "  # retrieve numpy array\n",
        "  dataset = data.values\n",
        "  # split into input (X) and output (y) variables\n",
        "  X = dataset[:, :-1]\n",
        "  y = dataset[:,-1]\n",
        "  return X, y\n",
        "\n",
        "# feature selection\n",
        "def select_features(X_train, y_train, X_test):\n",
        "  # configure to select all features\n",
        "  fs = SelectKBest(score_func=f_classif, k='all')\n",
        "  # learn relationship from training data\n",
        "  fs.fit(X_train, y_train)\n",
        "  # transform train input data\n",
        "  X_train_fs = fs.transform(X_train)\n",
        "  # transform test input data\n",
        "  X_test_fs = fs.transform(X_test)\n",
        "  return X_train_fs, X_test_fs, fs\n",
        "# load the dataset\n",
        "X, y = load_dataset('https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv')\n",
        "# split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "# feature selection\n",
        "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)\n",
        "# what are scores for the features\n",
        "for i in range(len(fs.scores_)):\n",
        "  print('Feature %d: %f' % (i, fs.scores_[i]))\n",
        "# plot the scores\n",
        "pyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
        "pyplot.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "dhX1fPYXaWVN",
        "outputId": "0eea0a39-ec86-4030-b47e-a9925cadfb04"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature 0: 16.527385\n",
            "Feature 1: 131.325562\n",
            "Feature 2: 0.042371\n",
            "Feature 3: 1.415216\n",
            "Feature 4: 12.778966\n",
            "Feature 5: 49.209523\n",
            "Feature 6: 13.377142\n",
            "Feature 7: 25.126440\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Mutual Information Feature Selection\n",
        "The scikit-learn machine learning library provides\n",
        "an implementation of mutual information for feature selection with numeric input and categorical\n",
        "output variables via the function \n",
        "`mutual_info_classif()`\n",
        ". \n",
        "Like \n",
        "`f_classif()`\n",
        "it can be used\n",
        "in the SelectKBest feature selection strategy (and other strategies)."
      ],
      "metadata": {
        "id": "0OBOr3ladiR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# example of mutual information feature selection for numerical input data\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from matplotlib import pyplot\n",
        "# load the dataset\n",
        "def load_dataset(filename):\n",
        "# load the dataset as a pandas DataFrame\n",
        "  data = read_csv(filename, header=None)\n",
        "  # retrieve numpy array\n",
        "  dataset = data.values\n",
        "  # split into input (X) and output (y) variables\n",
        "  X = dataset[:, :-1]\n",
        "  y = dataset[:,-1]\n",
        "  return X, y\n",
        "# feature selection\n",
        "def select_features(X_train, y_train, X_test):\n",
        "  # configure to select all features\n",
        "  fs = SelectKBest(score_func=mutual_info_classif, k='all')\n",
        "  # learn relationship from training data\n",
        "  fs.fit(X_train, y_train)\n",
        "  # transform train input data\n",
        "  X_train_fs = fs.transform(X_train)\n",
        "  # transform test input data\n",
        "  X_test_fs = fs.transform(X_test)\n",
        "  return X_train_fs, X_test_fs, fs\n",
        "# load the dataset\n",
        "X, y = load_dataset('https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv')\n",
        "# split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "# feature selection\n",
        "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)\n",
        "# what are scores for the features\n",
        "for i in range(len(fs.scores_)):\n",
        "  print('Feature %d: %f' % (i, fs.scores_[i]))\n",
        "# plot the scores\n",
        "pyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
        "pyplot.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "c1aoITuReayy",
        "outputId": "836cd181-8e59-41cb-c639-5046ec6e786d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature 0: 0.024239\n",
            "Feature 1: 0.102582\n",
            "Feature 2: 0.030731\n",
            "Feature 3: 0.006934\n",
            "Feature 4: 0.053357\n",
            "Feature 5: 0.076066\n",
            "Feature 6: 0.017017\n",
            "Feature 7: 0.040614\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Modeling with selected features"
      ],
      "metadata": {
        "id": "Nje9bcI8f99h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model built using all features\n",
        "First we create base line with all features and then compare with model based\n",
        "on features selected with ANOVA and mutual information."
      ],
      "metadata": {
        "id": "SPaM_-DagA9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation of a model using all input features\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "# load the dataset\n",
        "def load_dataset(filename):\n",
        "  # load the dataset as a pandas DataFrame\n",
        "  data = read_csv(filename, header=None)\n",
        "  # retrieve numpy array\n",
        "  dataset = data.values\n",
        "  # split into input (X) and output (y) variables\n",
        "  X = dataset[:, :-1]\n",
        "  y = dataset[:,-1]\n",
        "  return X, y\n",
        "# load the dataset\n",
        "X, y = load_dataset('https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv')\n",
        "# split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "# fit the model\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "model.fit(X_train, y_train)\n",
        "# evaluate the model\n",
        "yhat = model.predict(X_test)\n",
        "# evaluate predictions\n",
        "accuracy = accuracy_score(y_test, yhat)\n",
        "print('Accuracy: %.2f' % (accuracy*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFWUenV7gEQs",
        "outputId": "03e161ee-1239-4ae3-ae8f-32cf9a8b34af"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 77.56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model Built Using ANOVA F-test Features"
      ],
      "metadata": {
        "id": "2XXNveMfhRHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation of a model using 4 features chosen with anova f-test\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "# load the dataset\n",
        "def load_dataset(filename):\n",
        "  # load the dataset as a pandas DataFrame\n",
        "  data = read_csv(filename, header=None)\n",
        "  # retrieve numpy array\n",
        "  dataset = data.values\n",
        "  # split into input (X) and output (y) variables\n",
        "  X = dataset[:, :-1]\n",
        "  y = dataset[:,-1]\n",
        "  return X, y\n",
        "\n",
        "# feature selection\n",
        "def select_features(X_train, y_train, X_test):\n",
        "  # configure to select a subset of features\n",
        "  fs = SelectKBest(score_func=f_classif, k=4)\n",
        "  # learn relationship from training data\n",
        "  fs.fit(X_train, y_train)\n",
        "  # transform train input data\n",
        "  X_train_fs = fs.transform(X_train)\n",
        "  # transform test input data\n",
        "  X_test_fs = fs.transform(X_test)\n",
        "  return X_train_fs, X_test_fs, fs\n",
        "# load the dataset\n",
        "X, y = load_dataset('https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv')\n",
        "# split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "# feature selection\n",
        "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)\n",
        "# fit the model\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "model.fit(X_train_fs, y_train)\n",
        "# evaluate the model\n",
        "yhat = model.predict(X_test_fs)\n",
        "# evaluate predictions\n",
        "accuracy = accuracy_score(y_test, yhat)\n",
        "print('Accuracy: %.2f' % (accuracy*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9E8fXTHqhSO9",
        "outputId": "5d36132d-dd55-4fcb-cb97-55fed1abccdb"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 78.74\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model Built Using Mutual Information Features"
      ],
      "metadata": {
        "id": "oZUXpPPbiHeZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation of a model using 4 features chosen with mutual information\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "# load the dataset\n",
        "def load_dataset(filename):\n",
        "  # load the dataset as a pandas DataFrame\n",
        "  data = read_csv(filename, header=None)\n",
        "  # retrieve numpy array\n",
        "  dataset = data.values\n",
        "  # split into input (X) and output (y) variables\n",
        "  X = dataset[:, :-1]\n",
        "  y = dataset[:,-1]\n",
        "  return X, y\n",
        "# feature selection\n",
        "def select_features(X_train, y_train, X_test):\n",
        "  # configure to select a subset of features\n",
        "  fs = SelectKBest(score_func=mutual_info_classif, k=4)\n",
        "  # learn relationship from training data\n",
        "  fs.fit(X_train, y_train)\n",
        "  # transform train input data\n",
        "  X_train_fs = fs.transform(X_train)\n",
        "  # transform test input data\n",
        "  X_test_fs = fs.transform(X_test)\n",
        "  return X_train_fs, X_test_fs, fs\n",
        "# load the dataset\n",
        "X, y = load_dataset('https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv')\n",
        "# split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "# feature selection\n",
        "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)\n",
        "# fit the model\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "model.fit(X_train_fs, y_train)\n",
        "# evaluate the model\n",
        "yhat = model.predict(X_test_fs)\n",
        "# evaluate predictions\n",
        "accuracy = accuracy_score(y_test, yhat)\n",
        "print('Accuracy: %.2f' % (accuracy*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaXKR85oiI-e",
        "outputId": "3756a2c8-2156-49e9-c90f-2cc01e71829a"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 77.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Tune the Number of Selected Features"
      ],
      "metadata": {
        "id": "y91Ekr3QmTGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compare different numbers of features selected using anova f-test\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "# load the dataset\n",
        "def load_dataset(filename):\n",
        "  # load the dataset as a pandas DataFrame\n",
        "  data = read_csv(filename, header=None)\n",
        "  # retrieve numpy array\n",
        "  dataset = data.values\n",
        "  # split into input (X) and output (y) variables\n",
        "  X = dataset[:, :-1]\n",
        "  y = dataset[:,-1]\n",
        "  return X, y\n",
        "# define dataset\n",
        "X, y = load_dataset('https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv')\n",
        "# define the evaluation method\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "# define the pipeline to evaluate\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "fs = SelectKBest(score_func=f_classif)\n",
        "pipeline = Pipeline(steps=[('anova',fs), ('lr', model)])\n",
        "# define the grid\n",
        "grid = dict()\n",
        "grid['anova__k'] = [i+1 for i in range(X.shape[1])]\n",
        "# define the grid search\n",
        "search = GridSearchCV(pipeline, grid, scoring='accuracy', n_jobs=-1, cv=cv)\n",
        "# perform the search\n",
        "results = search.fit(X, y)\n",
        "# summarize best\n",
        "print('Best Mean Accuracy: %.3f' % results.best_score_)\n",
        "print('Best Config: %s' % results.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdOGf6k8mURA",
        "outputId": "2da53c4f-b0d9-4333-d17c-c3def114899e"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Mean Accuracy: 0.770\n",
            "Best Config: {'anova__k': 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compare different numbers of features selected using anova f-test\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from matplotlib import pyplot\n",
        "# load the dataset\n",
        "def load_dataset(filename):\n",
        "  # load the dataset as a pandas DataFrame\n",
        "  data = read_csv(filename, header=None)\n",
        "  # retrieve numpy array\n",
        "  dataset = data.values\n",
        "  # split into input (X) and output (y) variables\n",
        "  X = dataset[:, :-1]\n",
        "  y = dataset[:,-1]\n",
        "  return X, y\n",
        "# evaluate a given model using cross-validation\n",
        "def evaluate_model(model):\n",
        "  cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "  scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  return scores\n",
        "# define dataset\n",
        "X, y = load_dataset('https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv')\n",
        "# define number of features to evaluate\n",
        "num_features = [i+1 for i in range(X.shape[1])]\n",
        "# enumerate each number of features\n",
        "results = list()\n",
        "for k in num_features:\n",
        "  # create pipeline\n",
        "  model = LogisticRegression(solver='liblinear')\n",
        "  fs = SelectKBest(score_func=f_classif, k=k)\n",
        "  pipeline = Pipeline(steps=[('anova',fs), ('lr', model)])\n",
        "  # evaluate the model\n",
        "  scores = evaluate_model(pipeline)\n",
        "  results.append(scores)\n",
        "  # summarize the results\n",
        "  print('>%d %.3f (%.3f)' % (k, mean(scores), std(scores)))\n",
        "# plot model performance for comparison\n",
        "pyplot.boxplot(results, labels=num_features, showmeans=True)\n",
        "pyplot.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "EiG1T1hFnAZg",
        "outputId": "02ef6e17-4e30-45f8-e330-276a9442c448"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">1 0.748 (0.048)\n",
            ">2 0.756 (0.042)\n",
            ">3 0.761 (0.044)\n",
            ">4 0.759 (0.042)\n",
            ">5 0.770 (0.041)\n",
            ">6 0.766 (0.042)\n",
            ">7 0.770 (0.042)\n",
            ">8 0.768 (0.040)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DIMENSIONALITY REDUCTION TRAINING\n",
        "https://machinelearningmastery.com/dimensionality-reduction-algorithms-with-python/\n",
        "\n"
      ],
      "metadata": {
        "id": "2F_SxRTH83mR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtV4uTHD8lre",
        "outputId": "d2f58991-521d-4716-d3f4-caea026cb192"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 20) (1000,)\n"
          ]
        }
      ],
      "source": [
        "# synthetic classification dataset\n",
        "from sklearn.datasets import make_classification\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, n_redundant=10, random_state=7)\n",
        "# summarize the dataset\n",
        "print(X.shape, y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcKaqghGCrNy",
        "outputId": "ce9caae8-6955-4cc4-a861-5172c26efed6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.08054814,  0.82273313, -1.21175254, ...,  2.88260938,\n",
              "         1.79160028, -4.29708787],\n",
              "       [-2.3302999 , -4.86608574, -3.88291317, ..., -0.14561581,\n",
              "        -0.55489384,  0.61420772],\n",
              "       [-1.19714954,  1.5556314 , -0.61871573, ...,  1.73481788,\n",
              "         0.13067403, -3.13351468],\n",
              "       ...,\n",
              "       [ 0.61415067, -3.04457734, -3.15540898, ..., -0.3321506 ,\n",
              "        -2.76644911,  0.81460546],\n",
              "       [ 3.34221924, -1.33613258, -0.34013763, ..., -3.95225071,\n",
              "         1.33439536, -0.69139029],\n",
              "       [-1.49207892,  2.75225738, -1.22655776, ..., -3.10146388,\n",
              "         2.34534351, -1.32021006]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9KrOLjRCwSd",
        "outputId": "05db1ebf-221a-4469-f1d8-a74c13d6e042"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
              "       1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "       0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1,\n",
              "       1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "       1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0,\n",
              "       1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
              "       1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
              "       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "       1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0,\n",
              "       1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0,\n",
              "       1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
              "       1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
              "       1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "       1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
              "       1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1,\n",
              "       0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1,\n",
              "       0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
              "       1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
              "       1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1,\n",
              "       1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0,\n",
              "       1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "       0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "       1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1,\n",
              "       0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1,\n",
              "       1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1,\n",
              "       1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
              "       0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0,\n",
              "       1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0,\n",
              "       1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0,\n",
              "       0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
              "       1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0,\n",
              "       0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "       0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n",
              "       0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
              "       1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
              "       0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
              "       0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0,\n",
              "       0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "       1, 0, 0, 1, 0, 0, 1, 1, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate logistic regression model on raw data\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, n_redundant=10, random_state=7)\n",
        "# define the model\n",
        "model = LogisticRegression()\n",
        "# evaluate model\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "# report performance\n",
        "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_B-29IqfDG_e",
        "outputId": "4939951f-06cf-4d4d-8370-fc5194893678"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.824 (0.034)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PCA"
      ],
      "metadata": {
        "id": "gW_LukgHEzEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate pca with logistic regression algorithm for classification\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, n_redundant=10, random_state=7)\n",
        "# define the pipeline\n",
        "steps = [('pca', PCA(n_components=10)), ('m', LogisticRegression())]\n",
        "model = Pipeline(steps=steps)\n",
        "# evaluate model\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "# report performance\n",
        "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wa55iPIQExx_",
        "outputId": "ec2160d6-9343-4d25-d751-3dfe0d55c3d2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.824 (0.034)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SVD"
      ],
      "metadata": {
        "id": "4zXHuinwH6BH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate svd with logistic regression algorithm for classification\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, n_redundant=10, random_state=7)\n",
        "# define the pipeline\n",
        "steps = [('svd', TruncatedSVD(n_components=10)), ('m', LogisticRegression())]\n",
        "model = Pipeline(steps=steps)\n",
        "# evaluate model\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "# report performance\n",
        "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UNEGa-YH9Mo",
        "outputId": "ad85e45f-4c9b-427e-bc91-188bdecb76d9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.824 (0.034)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LDA\n",
        "The number of dimensions for the projection is limited to 1 and C-1, where C is the number of classes. In this case, our dataset is a binary classification problem (two classes), limiting the number of dimensions to 1."
      ],
      "metadata": {
        "id": "9SGfIjcCIVSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate lda with logistic regression algorithm for classification\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, n_redundant=10, random_state=7)\n",
        "# define the pipeline\n",
        "steps = [('lda', LinearDiscriminantAnalysis(n_components=1)), ('m', LogisticRegression())]\n",
        "model = Pipeline(steps=steps)\n",
        "# evaluate model\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "# report performance\n",
        "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltrjsNTWIWqJ",
        "outputId": "eb6a939f-ad70-4202-ea10-c7886e57265c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.825 (0.034)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Isomap Embedding"
      ],
      "metadata": {
        "id": "pT9whxevJUxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate isomap with logistic regression algorithm for classification\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.manifold import Isomap\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, n_redundant=10, random_state=7)\n",
        "# define the pipeline\n",
        "steps = [('iso', Isomap(n_components=10)), ('m', LogisticRegression())]\n",
        "model = Pipeline(steps=steps)\n",
        "# evaluate model\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "# report performance\n",
        "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8x9v2ACgJWOu",
        "outputId": "1378ac5b-7c22-427e-8f5d-9b0edb829f3f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.888 (0.029)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Locally Linear Embedding"
      ],
      "metadata": {
        "id": "x24EtYAZL-yi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate lle and logistic regression for classification\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.manifold import LocallyLinearEmbedding\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, n_redundant=10, random_state=7)\n",
        "# define the pipeline\n",
        "steps = [('lle', LocallyLinearEmbedding(n_components=10)), ('m', LogisticRegression())]\n",
        "model = Pipeline(steps=steps)\n",
        "# evaluate model\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "# report performance\n",
        "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eK_IFvGeL_vJ",
        "outputId": "34a07703-bdfe-4c99-c913-9c5d61c7ba99"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.886 (0.028)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Modified Locally Linear Embedding"
      ],
      "metadata": {
        "id": "8J8xvKdWMteT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embedding that can be used as a dimensionality reduction data transform. The “method” argument must be set to ‘modified’ and the “n_components” argument can be set to configure the number of desired dimensions in the output of the transform which must be less than the “n_neighbors” argument."
      ],
      "metadata": {
        "id": "xIzo1VA8ObIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate modified lle and logistic regression for classification\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.manifold import LocallyLinearEmbedding\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, n_redundant=10, random_state=7)\n",
        "# define the pipeline\n",
        "steps = [('lle', LocallyLinearEmbedding(n_components=5, method='modified', n_neighbors=10)), ('m', LogisticRegression())]\n",
        "model = Pipeline(steps=steps)\n",
        "# evaluate model\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "# report performance\n",
        "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6cqi2NiMuvM",
        "outputId": "e14fe633-27fc-4a0a-b98f-c4e99353be64"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.848 (0.037)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DIMENSIONALITY REDUCTION AND HYPERPARAMETERS\n",
        "https://towardsdatascience.com/shap-for-feature-selection-and-hyperparameter-tuning-a330ec0ea104\n"
      ],
      "metadata": {
        "id": "tel_dSxDP42S"
      }
    }
  ]
}